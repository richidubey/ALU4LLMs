{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! You have GPU access.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! You have GPU access.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. You do not have GPU access.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O4HLoBN3Swkc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/rdubey36/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model, GPT2Config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Block\n",
    "from typing import Optional, Tuple, Union # Import Optional, Tuple, and Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH8GtPLBdVe5"
   },
   "source": [
    "ALU implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "f8Btv-rvdTqc"
   },
   "outputs": [],
   "source": [
    "class ALU(torch.nn.Module):\n",
    "    def __init__(self, model_dim=768, hidden_dim=512, internal_dim=10, use_output_projection=False):\n",
    "        super(ALU, self).__init__()\n",
    "\n",
    "        # input mlp does model_dim -> hidden_dim -> hidden_dim -> (internal_dim * 2 + 4)\n",
    "        self.input_mlp = nn.Sequential(\n",
    "            nn.Linear(model_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, internal_dim * 2 + 4),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        if use_output_projection:\n",
    "            # output projection does 1 -> internal_dim -> hidden_dim -> model_dim\n",
    "            self.output_projection = nn.Sequential(\n",
    "                nn.Linear(1, internal_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(internal_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, model_dim)\n",
    "            )\n",
    "\n",
    "        self.eps = 1e-8\n",
    "        self.base = torch.tensor([1, 2, 4, 8, 16, 32, 64, 128, 256, 512])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"X-before: \", x.shape)\n",
    "        x = self.input_mlp(x)\n",
    "        a = x[:, :10]\n",
    "        b = x[:, 10:20]\n",
    "        op = x[:, 20:24]\n",
    "        # print(\"X-after: \", x.shape)\n",
    "        # print(\"A: \", a.shape)\n",
    "        # print(\"B: \", b.shape)\n",
    "        # print(\"OP: \", op.shape)\n",
    "        base = torch.tensor([1, 2, 4, 8, 16, 32, 64, 128, 256, 512], device=x.device, dtype=x.dtype)\n",
    "        a = torch.matmul(a, base)\n",
    "        b = torch.matmul(b, base)\n",
    "\n",
    "        op_weights = F.softmax(op, dim=1)  # Shape: (batch_size, 4)\n",
    "\n",
    "        add = a + b\n",
    "        sub = a - b\n",
    "        mul = a * b\n",
    "        div = a / (b + self.eps)\n",
    "\n",
    "        op_outs = torch.stack([add, sub, mul, div], dim=1)  # Shape: (batch_size, 4)\n",
    "        result = torch.sum(op_outs * op_weights, dim=1, keepdim=True)  # Shape: (batch_size, 1)\n",
    "\n",
    "        if hasattr(self, 'output_projection'):\n",
    "            result = self.output_projection(result)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBEfTankdbxj"
   },
   "source": [
    "Standard GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNon2Ds5YkEl",
    "outputId": "8f7a0522-a2b6-4d6b-9a78-aedc3b6823db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig, GPT2Config\n",
    "configuration = GPT2Config()\n",
    "model = GPT2LMHeadModel(configuration)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q-QFXCkb2pC"
   },
   "source": [
    "Modified GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BDbO08rWb6Gt"
   },
   "outputs": [],
   "source": [
    "class CustomGPT2Block(GPT2Block):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.alu = ALU(model_dim=config.n_embd, use_output_projection=True)\n",
    "        self.linear = nn.Linear(config.n_embd, config.n_embd)  # Linear\n",
    "        self.final_projection = nn.Linear(config.n_embd * 2, config.n_embd)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: Optional[Tuple[torch.FloatTensor]],\n",
    "        layer_past: Optional[Tuple[torch.Tensor]] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        use_cache: Optional[bool] = False,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Union[Tuple[torch.Tensor], Optional[Tuple[torch.Tensor, Tuple[torch.FloatTensor, ...]]]]:\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.ln_1(hidden_states)\n",
    "        attn_outputs = self.attn(\n",
    "            hidden_states,\n",
    "            layer_past=layer_past,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        attn_output = attn_outputs[0]  # output_attn: a, present, (attentions)\n",
    "        outputs = attn_outputs[1:]\n",
    "        # residual connection\n",
    "        hidden_states = attn_output + residual\n",
    "\n",
    "        if encoder_hidden_states is not None:\n",
    "            # add one self-attention block for cross-attention\n",
    "            if not hasattr(self, \"crossattention\"):\n",
    "                raise ValueError(\n",
    "                    f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with \"\n",
    "                    \"cross-attention layers by setting `config.add_cross_attention=True`\"\n",
    "                )\n",
    "            residual = hidden_states\n",
    "            hidden_states = self.ln_cross_attn(hidden_states)\n",
    "            cross_attn_outputs = self.crossattention(\n",
    "                hidden_states,\n",
    "                attention_mask=attention_mask,\n",
    "                head_mask=head_mask,\n",
    "                encoder_hidden_states=encoder_hidden_states,\n",
    "                encoder_attention_mask=encoder_attention_mask,\n",
    "                output_attentions=output_attentions,\n",
    "            )\n",
    "            attn_output = cross_attn_outputs[0]\n",
    "            # residual connection\n",
    "            hidden_states = residual + attn_output\n",
    "            outputs = outputs + cross_attn_outputs[2:]  # add cross attentions if we output attention weights\n",
    "\n",
    "        alu_hidden_states = self.linear(hidden_states) # NEW CODE: using a linear layer to transform the current hidden_state for alu computation\n",
    "        summed_alu_hidden_states = alu_hidden_states.sum(dim=1)  # NEW CODE: summing across dimension 1 (sequence length) Shape: [batch_size, embedding_dim]\n",
    "        alu_output = self.alu(summed_alu_hidden_states)     # NEW CODE: calling the ALU using the hidden_states\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.ln_2(hidden_states)\n",
    "        feed_forward_hidden_states = self.mlp(hidden_states)\n",
    "        # residual connection\n",
    "        hidden_states = residual + feed_forward_hidden_states\n",
    "        hidden_states = torch.cat([hidden_states, alu_output.unsqueeze(1).expand(-1, hidden_states.size(1), -1)], dim=-1) # NEW CODE: concatenating the ALU output to the hidden states\n",
    "        hidden_states = self.final_projection(hidden_states)  # NEW CODE: projecting the hidden_state to the required dimension\n",
    "        outputs = (hidden_states,) + outputs\n",
    "\n",
    "        if use_cache:\n",
    "            outputs = (hidden_states,) + outputs\n",
    "        else:\n",
    "            outputs = (hidden_states,) + outputs[1:]\n",
    "\n",
    "        return outputs  # hidden_states, present, (attentions, cross_attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z_5hmrIkcBv0"
   },
   "outputs": [],
   "source": [
    "class CustomGPT2Model(GPT2LMHeadModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.transformer = GPT2Model(config)\n",
    "        num_layers = len(self.transformer.h)\n",
    "        for i in range(num_layers - 3, num_layers):\n",
    "            self.transformer.h[i] = CustomGPT2Block(config)\n",
    "        \n",
    "        #Add LM head\n",
    "        #self.lm_head = torch.nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, input_ids=None, past_key_values=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, encoder_hidden_states=None, encoder_attention_mask=None, labels=None, use_cache=None, output_attentions=None, output_hidden_states=None, return_dict=None):\n",
    "        \n",
    "        return super().forward(\n",
    "            input_ids,\n",
    "            past_key_values, \n",
    "            attention_mask, \n",
    "            token_type_ids, \n",
    "            position_ids, \n",
    "            head_mask, \n",
    "            inputs_embeds, \n",
    "            encoder_hidden_states, \n",
    "            encoder_attention_mask, \n",
    "            labels,\n",
    "            use_cache, \n",
    "            output_attentions, \n",
    "            output_hidden_states, \n",
    "            return_dict)\n",
    "    \n",
    "        # hidden_states = outputs.last_hidden_state\n",
    "        # logits = self.lm_head(hidden_states)\n",
    "\n",
    "        # return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y--X2HVdcJL7",
    "outputId": "c1eecea2-a4c7-4a03-d66f-d49c99143f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomGPT2Model(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-8): 9 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9-11): 3 x CustomGPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (alu): ALU(\n",
      "          (input_mlp): Sequential(\n",
      "            (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.01)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.01)\n",
      "            (4): Linear(in_features=512, out_features=24, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "          (output_projection): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=10, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=10, out_features=512, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=512, out_features=768, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (final_projection): Linear(in_features=1536, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model2 = CustomGPT2Model(configuration)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYcll4KAcgcx"
   },
   "source": [
    "Later to load the weights (Need to verify this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379,
     "referenced_widgets": [
      "40d06beaf3184bab820b838f307eced0",
      "f1b7aa63a2b54b0da9fbb42cf150224f",
      "2e528a25513642a1bdc357462a93d6f3",
      "a661439821e644c489abdf913dde2f7f",
      "228a14a890c74f81a58ecf89759b2539",
      "ddf6e3191347473ab221282bc6befa06",
      "f1edee125e2145a0aaccdbcebcd5184e",
      "ca9af9908ea1428fb9e3a7463a53b78b",
      "87a5ba1d542b46668992e5d4f07909b7",
      "05f5aa7d478e4fc4a766718438cae2de",
      "1ea78e20a596498c834fb068380c2a44",
      "485bbc552f87497e80485c868face717",
      "d25b4beee8524b5db6c24d791165f9c4",
      "3dc783062d1d48339ce06229684cacba",
      "d91d67a1f0154660adbda90e3a4121ed",
      "5909802c97724dcebba8268a0a511677",
      "201b97b8813d41a4b7661d9f92e098ab",
      "527f56197cd649288b70c0f5d5510117",
      "b970dbe014d243299e909c5b954e02c4",
      "3799256f111445e8b19eb4c7da57f16d",
      "2c8b07c27f3242c8884aafe596e6a78d",
      "6db22affb0f74625bb174564a940a4e5"
     ]
    },
    "id": "MsEAWHjxcikD",
    "outputId": "8e510c21-3850-4f87-beac-85f6bb7af6e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['transformer.wte.weight', 'transformer.wpe.weight', 'transformer.h.0.ln_1.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.0.attn.c_attn.weight', 'transformer.h.0.attn.c_attn.bias', 'transformer.h.0.attn.c_proj.weight', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.2.attn.c_attn.weight', 'transformer.h.2.attn.c_attn.bias', 'transformer.h.2.attn.c_proj.weight', 'transformer.h.2.attn.c_proj.bias', 'transformer.h.2.ln_2.weight', 'transformer.h.2.ln_2.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.3.attn.c_attn.weight', 'transformer.h.3.attn.c_attn.bias', 'transformer.h.3.attn.c_proj.weight', 'transformer.h.3.attn.c_proj.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.4.ln_1.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.4.attn.c_attn.weight', 'transformer.h.4.attn.c_attn.bias', 'transformer.h.4.attn.c_proj.weight', 'transformer.h.4.attn.c_proj.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.5.attn.c_attn.weight', 'transformer.h.5.attn.c_attn.bias', 'transformer.h.5.attn.c_proj.weight', 'transformer.h.5.attn.c_proj.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.6.ln_1.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.6.attn.c_attn.weight', 'transformer.h.6.attn.c_attn.bias', 'transformer.h.6.attn.c_proj.weight', 'transformer.h.6.attn.c_proj.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.6.ln_2.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.7.attn.c_attn.weight', 'transformer.h.7.attn.c_attn.bias', 'transformer.h.7.attn.c_proj.weight', 'transformer.h.7.attn.c_proj.bias', 'transformer.h.7.ln_2.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.8.ln_1.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.8.attn.c_attn.weight', 'transformer.h.8.attn.c_attn.bias', 'transformer.h.8.attn.c_proj.weight', 'transformer.h.8.attn.c_proj.bias', 'transformer.h.8.ln_2.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.9.attn.c_attn.weight', 'transformer.h.9.attn.c_attn.bias', 'transformer.h.9.attn.c_proj.weight', 'transformer.h.9.attn.c_proj.bias', 'transformer.h.9.ln_2.weight', 'transformer.h.9.ln_2.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.9.alu.input_mlp.0.weight', 'transformer.h.9.alu.input_mlp.0.bias', 'transformer.h.9.alu.input_mlp.2.weight', 'transformer.h.9.alu.input_mlp.2.bias', 'transformer.h.9.alu.input_mlp.4.weight', 'transformer.h.9.alu.input_mlp.4.bias', 'transformer.h.9.alu.output_projection.0.weight', 'transformer.h.9.alu.output_projection.0.bias', 'transformer.h.9.alu.output_projection.2.weight', 'transformer.h.9.alu.output_projection.2.bias', 'transformer.h.9.alu.output_projection.4.weight', 'transformer.h.9.alu.output_projection.4.bias', 'transformer.h.9.linear.weight', 'transformer.h.9.linear.bias', 'transformer.h.9.final_projection.weight', 'transformer.h.9.final_projection.bias', 'transformer.h.10.ln_1.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.10.attn.c_attn.weight', 'transformer.h.10.attn.c_attn.bias', 'transformer.h.10.attn.c_proj.weight', 'transformer.h.10.attn.c_proj.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.10.alu.input_mlp.0.weight', 'transformer.h.10.alu.input_mlp.0.bias', 'transformer.h.10.alu.input_mlp.2.weight', 'transformer.h.10.alu.input_mlp.2.bias', 'transformer.h.10.alu.input_mlp.4.weight', 'transformer.h.10.alu.input_mlp.4.bias', 'transformer.h.10.alu.output_projection.0.weight', 'transformer.h.10.alu.output_projection.0.bias', 'transformer.h.10.alu.output_projection.2.weight', 'transformer.h.10.alu.output_projection.2.bias', 'transformer.h.10.alu.output_projection.4.weight', 'transformer.h.10.alu.output_projection.4.bias', 'transformer.h.10.linear.weight', 'transformer.h.10.linear.bias', 'transformer.h.10.final_projection.weight', 'transformer.h.10.final_projection.bias', 'transformer.h.11.ln_1.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.11.attn.c_attn.weight', 'transformer.h.11.attn.c_attn.bias', 'transformer.h.11.attn.c_proj.weight', 'transformer.h.11.attn.c_proj.bias', 'transformer.h.11.ln_2.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.11.alu.input_mlp.0.weight', 'transformer.h.11.alu.input_mlp.0.bias', 'transformer.h.11.alu.input_mlp.2.weight', 'transformer.h.11.alu.input_mlp.2.bias', 'transformer.h.11.alu.input_mlp.4.weight', 'transformer.h.11.alu.input_mlp.4.bias', 'transformer.h.11.alu.output_projection.0.weight', 'transformer.h.11.alu.output_projection.0.bias', 'transformer.h.11.alu.output_projection.2.weight', 'transformer.h.11.alu.output_projection.2.bias', 'transformer.h.11.alu.output_projection.4.weight', 'transformer.h.11.alu.output_projection.4.bias', 'transformer.h.11.linear.weight', 'transformer.h.11.linear.bias', 'transformer.h.11.final_projection.weight', 'transformer.h.11.final_projection.bias', 'transformer.ln_f.weight', 'transformer.ln_f.bias', 'lm_head.weight'], unexpected_keys=['wte.weight', 'wpe.weight', 'h.0.ln_1.weight', 'h.0.ln_1.bias', 'h.0.attn.c_attn.weight', 'h.0.attn.c_attn.bias', 'h.0.attn.c_proj.weight', 'h.0.attn.c_proj.bias', 'h.0.ln_2.weight', 'h.0.ln_2.bias', 'h.0.mlp.c_fc.weight', 'h.0.mlp.c_fc.bias', 'h.0.mlp.c_proj.weight', 'h.0.mlp.c_proj.bias', 'h.1.ln_1.weight', 'h.1.ln_1.bias', 'h.1.attn.c_attn.weight', 'h.1.attn.c_attn.bias', 'h.1.attn.c_proj.weight', 'h.1.attn.c_proj.bias', 'h.1.ln_2.weight', 'h.1.ln_2.bias', 'h.1.mlp.c_fc.weight', 'h.1.mlp.c_fc.bias', 'h.1.mlp.c_proj.weight', 'h.1.mlp.c_proj.bias', 'h.2.ln_1.weight', 'h.2.ln_1.bias', 'h.2.attn.c_attn.weight', 'h.2.attn.c_attn.bias', 'h.2.attn.c_proj.weight', 'h.2.attn.c_proj.bias', 'h.2.ln_2.weight', 'h.2.ln_2.bias', 'h.2.mlp.c_fc.weight', 'h.2.mlp.c_fc.bias', 'h.2.mlp.c_proj.weight', 'h.2.mlp.c_proj.bias', 'h.3.ln_1.weight', 'h.3.ln_1.bias', 'h.3.attn.c_attn.weight', 'h.3.attn.c_attn.bias', 'h.3.attn.c_proj.weight', 'h.3.attn.c_proj.bias', 'h.3.ln_2.weight', 'h.3.ln_2.bias', 'h.3.mlp.c_fc.weight', 'h.3.mlp.c_fc.bias', 'h.3.mlp.c_proj.weight', 'h.3.mlp.c_proj.bias', 'h.4.ln_1.weight', 'h.4.ln_1.bias', 'h.4.attn.c_attn.weight', 'h.4.attn.c_attn.bias', 'h.4.attn.c_proj.weight', 'h.4.attn.c_proj.bias', 'h.4.ln_2.weight', 'h.4.ln_2.bias', 'h.4.mlp.c_fc.weight', 'h.4.mlp.c_fc.bias', 'h.4.mlp.c_proj.weight', 'h.4.mlp.c_proj.bias', 'h.5.ln_1.weight', 'h.5.ln_1.bias', 'h.5.attn.c_attn.weight', 'h.5.attn.c_attn.bias', 'h.5.attn.c_proj.weight', 'h.5.attn.c_proj.bias', 'h.5.ln_2.weight', 'h.5.ln_2.bias', 'h.5.mlp.c_fc.weight', 'h.5.mlp.c_fc.bias', 'h.5.mlp.c_proj.weight', 'h.5.mlp.c_proj.bias', 'h.6.ln_1.weight', 'h.6.ln_1.bias', 'h.6.attn.c_attn.weight', 'h.6.attn.c_attn.bias', 'h.6.attn.c_proj.weight', 'h.6.attn.c_proj.bias', 'h.6.ln_2.weight', 'h.6.ln_2.bias', 'h.6.mlp.c_fc.weight', 'h.6.mlp.c_fc.bias', 'h.6.mlp.c_proj.weight', 'h.6.mlp.c_proj.bias', 'h.7.ln_1.weight', 'h.7.ln_1.bias', 'h.7.attn.c_attn.weight', 'h.7.attn.c_attn.bias', 'h.7.attn.c_proj.weight', 'h.7.attn.c_proj.bias', 'h.7.ln_2.weight', 'h.7.ln_2.bias', 'h.7.mlp.c_fc.weight', 'h.7.mlp.c_fc.bias', 'h.7.mlp.c_proj.weight', 'h.7.mlp.c_proj.bias', 'h.8.ln_1.weight', 'h.8.ln_1.bias', 'h.8.attn.c_attn.weight', 'h.8.attn.c_attn.bias', 'h.8.attn.c_proj.weight', 'h.8.attn.c_proj.bias', 'h.8.ln_2.weight', 'h.8.ln_2.bias', 'h.8.mlp.c_fc.weight', 'h.8.mlp.c_fc.bias', 'h.8.mlp.c_proj.weight', 'h.8.mlp.c_proj.bias', 'h.9.ln_1.weight', 'h.9.ln_1.bias', 'h.9.attn.c_attn.weight', 'h.9.attn.c_attn.bias', 'h.9.attn.c_proj.weight', 'h.9.attn.c_proj.bias', 'h.9.ln_2.weight', 'h.9.ln_2.bias', 'h.9.mlp.c_fc.weight', 'h.9.mlp.c_fc.bias', 'h.9.mlp.c_proj.weight', 'h.9.mlp.c_proj.bias', 'h.10.ln_1.weight', 'h.10.ln_1.bias', 'h.10.attn.c_attn.weight', 'h.10.attn.c_attn.bias', 'h.10.attn.c_proj.weight', 'h.10.attn.c_proj.bias', 'h.10.ln_2.weight', 'h.10.ln_2.bias', 'h.10.mlp.c_fc.weight', 'h.10.mlp.c_fc.bias', 'h.10.mlp.c_proj.weight', 'h.10.mlp.c_proj.bias', 'h.11.ln_1.weight', 'h.11.ln_1.bias', 'h.11.attn.c_attn.weight', 'h.11.attn.c_attn.bias', 'h.11.attn.c_proj.weight', 'h.11.attn.c_proj.bias', 'h.11.ln_2.weight', 'h.11.ln_2.bias', 'h.11.mlp.c_fc.weight', 'h.11.mlp.c_fc.bias', 'h.11.mlp.c_proj.weight', 'h.11.mlp.c_proj.bias', 'ln_f.weight', 'ln_f.bias'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = GPT2Config.from_pretrained('gpt2')\n",
    "customModel = CustomGPT2Model(config)\n",
    "\n",
    "# If you want to load pre-trained weights:\n",
    "state_dict = GPT2Model.from_pretrained('gpt2').state_dict()\n",
    "customModel.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomGPT2Model(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-8): 9 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9-11): 3 x CustomGPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (alu): ALU(\n",
       "          (input_mlp): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.01)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.01)\n",
       "            (4): Linear(in_features=512, out_features=24, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.01)\n",
       "          )\n",
       "          (output_projection): Sequential(\n",
       "            (0): Linear(in_features=1, out_features=10, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=10, out_features=512, bias=True)\n",
       "            (3): ReLU()\n",
       "            (4): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (final_projection): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: Once upon a time, spawn\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Config, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "customModel.eval()\n",
    "input_text = \"Once upon a time,\"\n",
    "\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")[\"input_ids\"].to(customModel.device)\n",
    "#print(\"Device of input ids is\", input_ids.device)\n",
    "# with torch.no_grad():\n",
    "#     logits = customModel(input_ids=input_ids)\n",
    "\n",
    "output_ids = customModel.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=6,  # Maximum length of generated text\n",
    "    num_return_sequences=1,  # Number of sequences to generate\n",
    "    do_sample=True,  # Enable sampling\n",
    "    top_k=50,  # Use top-k sampling\n",
    "    temperature=0.7,  # Sampling temperature\n",
    ")\n",
    "\n",
    "predicted_ids = output_ids\n",
    "\n",
    "generated_text = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataset to finetune\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "\n",
    "class ArithmeticDataset(IterableDataset):\n",
    "    def __init__(self, min_val=0, max_val=256):\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "        \n",
    "        self.operations = {\n",
    "            0: lambda x, y: x + y,    # addition\n",
    "            1: lambda x, y: x - y,    # subtraction\n",
    "            2: lambda x, y: x * y,    # multiplication\n",
    "            3: lambda x, y: x / (y + 1e-8)  # division\n",
    "        }\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            # Generate random numbers\n",
    "            num1 = torch.rand(1) * (self.max_val - self.min_val) + self.min_val\n",
    "            num2 = torch.rand(1) * (self.max_val - self.min_val) + self.min_val\n",
    "            \n",
    "            # Generate random operations\n",
    "            op_idx = torch.tensor([0]) # torch.randint(0, 4, (1,))\n",
    "            operation = F.one_hot(op_idx, num_classes=4).float()\n",
    "            \n",
    "            # Calculate targets\n",
    "            target = self.operations[op_idx.item()](num1, num2)            \n",
    "            \n",
    "            yield num1, num2, operation.squeeze(0), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([241.6788]), tensor([249.2799]), tensor([1., 0., 0., 0.]), tensor([490.9587]))\n",
      "[tensor([[133.8290],\n",
      "        [ 29.2392]]), tensor([[ 87.0907],\n",
      "        [103.3537]]), tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]), tensor([[220.9198],\n",
      "        [132.5928]])]\n"
     ]
    }
   ],
   "source": [
    "ad = ArithmeticDataset()\n",
    "print(next(iter(ad)))\n",
    "dataloader = torch.utils.data.DataLoader(ad, batch_size=2)\n",
    "print(next(iter(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrichidubey\u001b[0m (\u001b[33mrichidubey-georgia-institute-of-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "from torch.utils.data import DataLoader\n",
    "wandb.require(\"service\")\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2Config, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "def arithmetic_loss(predictions, targets, scale_factor=10000.0):\n",
    "    abs_error = (predictions - targets)**2\n",
    "    # rel_error = torch.abs((predictions - targets) / (targets + 1e-8)) * scale_factor\n",
    "    loss = abs_error # + rel_error\n",
    "    return torch.sum(loss)\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    num_epochs=6000,\n",
    "    batch_size=1024,\n",
    "    initial_lr=1e-3,\n",
    "    device='cuda',\n",
    "    # eval_every=500,\n",
    "    use_wandb=False,\n",
    "    project_name=\"arithmetic_training\"\n",
    "):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=initial_lr)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.7)\n",
    "    \n",
    "    dataset = ArithmeticDataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=1, pin_memory=True, persistent_workers=True)\n",
    "    \n",
    "    steps_per_epoch = 1000\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    # Initialize logging\n",
    "    if use_wandb:\n",
    "        wandb.init(project=project_name)\n",
    "        wandb.config.update({\n",
    "            \"learning_rate\": initial_lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"scheduler_step_size\": 200,\n",
    "            \"scheduler_gamma\": 0.7\n",
    "        })\n",
    "    else:\n",
    "        # Create CSV log file with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        log_file = f'training_log_{timestamp}.csv'\n",
    "        log_data = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_losses = []\n",
    "        epoch_diffs = []\n",
    "        \n",
    "        data_iter = iter(dataloader)\n",
    "        pbar = tqdm(range(steps_per_epoch), desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for step in pbar:\n",
    "            try:\n",
    "                batch = next(data_iter)\n",
    "            except StopIteration:\n",
    "                data_iter = iter(dataloader)\n",
    "                batch = next(data_iter)\n",
    "            \n",
    "            num1, num2, operation, targets = [item.to(device) for item in batch]\n",
    "            \n",
    "            # num1 = num1.unsqueeze(1)\n",
    "            # num2 = num2.unsqueeze(1)\n",
    "            ###############################\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # inp_txt = str(num1) + str(operation) + str(num2)\n",
    "\n",
    "            \n",
    "\n",
    "            operation_mapping = {0: \"+\", 1: \"-\", 2: \"*\", 3: \"/\"}\n",
    "\n",
    "            # Decode the one-hot tensor into operation symbols\n",
    "            decoded_operations = [operation_mapping[torch.argmax(op).item()] for op in operation]\n",
    "\n",
    "            inp_txt = [\n",
    "                f\"{num1.item()} {op} {num2.item()}\" for num1, op, num2 in zip(num1, decoded_operations, num2)\n",
    "            ]\n",
    "\n",
    "            print(\"INp text is \", inp_txt)\n",
    "\n",
    "            input_ids = tokenizer(inp_txt, return_tensors=\"pt\", padding=True, truncation = True)[\"input_ids\"].to(model.device)\n",
    "\n",
    "            # print(\"num1 is\", num1)\n",
    "            # print(\"num2 is\", num2 )\n",
    "            # print(\"op is\", operation)\n",
    "\n",
    "            # print(\"inp_txt is\", inp_txt)\n",
    "\n",
    "            # print(\"input_ids has shape\", input_ids.shape)\n",
    "            print(\"Input ids has shape\", input_ids)\n",
    "\n",
    "            output_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=4,  # Maximum length of generated text\n",
    "                num_return_sequences=1,  # Number of sequences to generate\n",
    "                do_sample=True,  # Enable sampling\n",
    "                top_k=50,  # Use top-k sampling\n",
    "                temperature=0.7,  # Sampling temperature\n",
    "            )\n",
    "\n",
    "            predicted_ids = output_ids\n",
    "\n",
    "            # print(\"Shape of logits is\", logits.shape)\n",
    "            # print(\"Shape of predicted ids is\", predicted_ids.shape)\n",
    "\n",
    "            predictions = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)[-1]\n",
    "\n",
    "\n",
    "            # logits = customModel(input_ids=input_ids)\n",
    "\n",
    "            # predicted_ids = torch.argmax(logits, dim=-1)\n",
    "            # predictions = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "\n",
    "            ################################\n",
    "\n",
    "            try: \n",
    "                numeric_prediction = float(predictions)  # Only if it should be a number\n",
    "                predictions_tensor = torch.tensor([numeric_prediction]).to(device)  # Convert to tensor\n",
    "            except ValueError:\n",
    "                # print(f\"Decoded output is not numeric: {predictions}\")\n",
    "                predictions_tensor = torch.tensor([0.0], device=device, requires_grad=True)\n",
    "                \n",
    "            predictions =  predictions_tensor\n",
    "            loss = arithmetic_loss(predictions, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                diffs = torch.abs(predictions - targets)\n",
    "                epoch_diffs.extend(diffs.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({'Loss': loss.item()})\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            test_num1, test_num2, test_op, test_targets = [item.to(device) for item in next(iter(dataloader))]\n",
    "\n",
    "            ########################################\n",
    "\n",
    "            operation_mapping = {0: \"+\", 1: \"-\", 2: \"*\", 3: \"/\"}\n",
    "\n",
    "            # Decode the one-hot tensor into operation symbols\n",
    "            decoded_operations = [operation_mapping[torch.argmax(op).item()] for op in test_op]\n",
    "\n",
    "\n",
    "            inp_txt = [\n",
    "                f\"{num1.item()} {op.item()} {num2.item()}\" for num1, op, num2 in zip(test_num1, decoded_operations, test_num2)\n",
    "            ]\n",
    "        \n",
    "            input_ids = tokenizer(inp_txt, return_tensors=\"pt\")[\"input_ids\"].to(model.device)\n",
    "            \n",
    "            output_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=4,  # Maximum length of generated text\n",
    "                num_return_sequences=1,  # Number of sequences to generate\n",
    "                do_sample=True,  # Enable sampling\n",
    "                top_k=50,  # Use top-k sampling\n",
    "                temperature=0.7,  # Sampling temperature\n",
    "            )\n",
    "\n",
    "            predicted_ids = output_ids\n",
    "\n",
    "            # print(\"Shape of logits is\", logits.shape)\n",
    "            # print(\"Shape of predicted ids is\", predicted_ids.shape)\n",
    "\n",
    "            predictions = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)[-1]\n",
    "\n",
    "            try: \n",
    "                numeric_prediction = float(predictions)  # Only if it should be a number\n",
    "                predictions_tensor = torch.tensor([numeric_prediction]).to(device)  # Convert to tensor\n",
    "            except ValueError:\n",
    "                # print(f\"Decoded output is not numeric: {predictions}\")\n",
    "                predictions_tensor = torch.tensor([0.0], device=device, requires_grad=True)\n",
    "                \n",
    "            test_pred =  predictions_tensor\n",
    "            ####################################################\n",
    "            \n",
    "            test_loss = arithmetic_loss(test_pred, test_targets)\n",
    "           \n",
    "            first_pred = test_pred[0].item()\n",
    "            first_target = test_targets[0].item()\n",
    "            \n",
    "            # Format to 5 decimal places\n",
    "            first_pred_formatted = f\"{first_pred:.5f}\"\n",
    "            first_target_formatted = f\"{first_target:.5f}\"\n",
    "            \n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            train_loss = np.mean(epoch_losses)\n",
    "            val_loss = test_loss.item()\n",
    "            avg_diff = np.mean(epoch_diffs)\n",
    "            median_diff = np.median(epoch_diffs)\n",
    "            \n",
    "            if use_wandb:\n",
    "                wandb.log({\n",
    "                    'learning_rate': current_lr,\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                    'avg_prediction_diff': avg_diff,\n",
    "                    'median_prediction_diff': median_diff,\n",
    "                    'epoch': epoch + 1\n",
    "                })\n",
    "            else:\n",
    "                log_data.append({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'learning_rate': current_lr,\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                    'avg_prediction_diff': avg_diff,\n",
    "                    'median_prediction_diff': median_diff\n",
    "                })\n",
    "            \n",
    "            print(\n",
    "                f'Epoch {epoch+1}/{num_epochs} | '\n",
    "                f'LR: {current_lr:.2e} | '\n",
    "                f'Train Loss: {train_loss:.4f} | '\n",
    "                f'Val Loss: {val_loss:.4f} | '\n",
    "                f'Avg Diff: {avg_diff:.4f} | '\n",
    "                f'First Pred: {first_pred_formatted} | '\n",
    "                f'First Target: {first_target_formatted}'\n",
    "            )\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        # Save the best model\n",
    "        if train_loss < best_loss:\n",
    "            best_loss = train_loss\n",
    "            torch.save(model.state_dict(), 'best_arithmetic_model.pt')\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1} completed. Average loss: {train_loss:.4f}\\n')\n",
    "    \n",
    "    if not use_wandb:\n",
    "        pd.DataFrame(log_data).to_csv(log_file, index=False)\n",
    "        print(f\"Training log saved to {log_file}\")\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|                                                                                                                      | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INp text is  ['39.44532775878906 + 56.15846252441406', '182.74403381347656 + 161.368408203125', '87.34925842285156 + 171.78358459472656', '92.96932983398438 + 241.03765869140625', '156.76275634765625 + 187.2506866455078', '128.2958526611328 + 64.32244873046875', '110.33406066894531 + 227.0379638671875', '175.83277893066406 + 211.7412567138672', '213.18832397460938 + 219.33740234375', '94.76513671875 + 49.940093994140625', '119.56062316894531 + 52.02989196777344', '194.41751098632812 + 232.977783203125', '190.35797119140625 + 80.49978637695312', '122.58100891113281 + 25.713546752929688', '19.692047119140625 + 138.43807983398438', '142.10028076171875 + 44.06886291503906', '218.4680633544922 + 69.15025329589844', '63.6024169921875 + 69.93028259277344', '55.15858459472656 + 129.18702697753906', '66.25399780273438 + 136.5983123779297', '244.0214385986328 + 152.60360717773438', '205.21202087402344 + 28.924270629882812', '17.752227783203125 + 60.75213623046875', '15.243072509765625 + 46.9990234375', '101.75595092773438 + 133.8807830810547', '176.66098022460938 + 159.14111328125', '172.3592987060547 + 148.42001342773438', '94.28068542480469 + 1.9193572998046875', '194.07542419433594 + 133.98370361328125', '30.866653442382812 + 174.44976806640625', '169.10447692871094 + 136.92288208007812', '251.33091735839844 + 151.94369506835938', '158.97193908691406 + 189.9347686767578', '159.4194793701172 + 124.1815185546875', '45.30137634277344 + 1.3248443603515625', '94.54478454589844 + 137.71873474121094', '87.40237426757812 + 40.39094543457031', '168.66506958007812 + 40.37638854980469', '190.73477172851562 + 65.95027160644531', '154.74757385253906 + 241.05490112304688', '52.1787109375 + 243.71380615234375', '114.09446716308594 + 84.51844787597656', '43.82647705078125 + 3.0524749755859375', '167.80923461914062 + 60.83213806152344', '71.7164306640625 + 209.78372192382812', '28.295028686523438 + 31.016632080078125', '26.13922119140625 + 205.8362274169922', '165.20298767089844 + 190.54421997070312', '160.82177734375 + 230.2693328857422', '106.02389526367188 + 79.98207092285156', '203.12672424316406 + 191.5447998046875', '209.14041137695312 + 27.826248168945312', '238.75636291503906 + 25.756088256835938', '195.0176544189453 + 6.347564697265625', '83.036376953125 + 100.06932067871094', '172.69671630859375 + 6.6478271484375', '195.09324645996094 + 107.46739196777344', '98.14114379882812 + 108.22698974609375', '205.5624237060547 + 114.60659790039062', '12.56048583984375 + 116.45901489257812', '42.489593505859375 + 243.8234100341797', '73.4486083984375 + 224.2651824951172', '109.63874816894531 + 97.75694274902344', '119.7728271484375 + 104.16595458984375', '32.10386657714844 + 191.17164611816406', '199.8036346435547 + 50.16114807128906', '90.47019958496094 + 45.074462890625', '72.79696655273438 + 156.6994171142578', '11.397171020507812 + 219.83302307128906', '197.19692993164062 + 231.37277221679688', '206.9671630859375 + 127.15374755859375', '50.73774719238281 + 0.428802490234375', '137.24728393554688 + 212.8943634033203', '106.79092407226562 + 77.33999633789062', '222.50515747070312 + 125.71446228027344', '147.1629638671875 + 182.28639221191406', '96.88990783691406 + 3.8182525634765625', '200.57420349121094 + 225.1696014404297', '175.73243713378906 + 207.31597900390625', '54.046417236328125 + 105.00454711914062', '144.4580535888672 + 5.5392913818359375', '7.638641357421875 + 79.51606750488281', '43.884063720703125 + 161.6908416748047', '78.04267883300781 + 5.6670379638671875', '42.82916259765625 + 81.99153137207031', '71.46835327148438 + 147.75042724609375', '10.035888671875 + 172.96328735351562', '240.96347045898438 + 165.01788330078125', '227.07643127441406 + 8.708023071289062', '37.546661376953125 + 159.03097534179688', '187.23753356933594 + 65.97154235839844', '187.2815399169922 + 201.2231903076172', '18.583404541015625 + 38.250030517578125', '243.08367919921875 + 152.66665649414062', '220.7823944091797 + 11.850692749023438', '173.99488830566406 + 148.425048828125', '126.60818481445312 + 252.8179473876953', '252.9290008544922 + 28.018417358398438', '217.33859252929688 + 68.38873291015625', '130.62176513671875 + 146.79061889648438', '78.12516784667969 + 211.76031494140625', '105.32331848144531 + 233.9200439453125', '253.3544921875 + 10.052841186523438', '201.88197326660156 + 166.56085205078125', '233.4739532470703 + 59.27189636230469', '145.4316864013672 + 22.945877075195312', '16.39691162109375 + 37.62931823730469', '132.29563903808594 + 186.46327209472656', '125.49365234375 + 139.23533630371094', '231.1820831298828 + 180.11587524414062', '185.64146423339844 + 15.676025390625', '144.99713134765625 + 225.35618591308594', '44.99261474609375 + 207.80093383789062', '98.90199279785156 + 154.22665405273438', '118.25804138183594 + 165.8836212158203', '210.3075714111328 + 189.2360382080078', '39.60499572753906 + 69.39833068847656', '121.07614135742188 + 253.20457458496094', '16.628158569335938 + 203.99313354492188', '147.7807159423828 + 34.48876953125', '210.12289428710938 + 107.87565612792969', '20.072174072265625 + 224.53111267089844', '203.58277893066406 + 163.51564025878906', '55.450958251953125 + 192.32723999023438', '151.32528686523438 + 219.34503173828125', '230.3284912109375 + 205.01817321777344', '193.65615844726562 + 94.79962158203125', '20.30523681640625 + 13.64678955078125', '155.32945251464844 + 207.5835723876953', '212.56454467773438 + 192.55189514160156', '184.96839904785156 + 116.21388244628906', '137.08226013183594 + 156.5475616455078', '72.79277038574219 + 200.225830078125', '233.7675018310547 + 105.01910400390625', '193.98391723632812 + 2.3955841064453125', '140.363037109375 + 122.18280029296875', '96.22434997558594 + 171.05052185058594', '150.9566650390625 + 34.442840576171875', '154.13922119140625 + 204.0446014404297', '152.87852478027344 + 123.95132446289062', '116.54475402832031 + 180.44837951660156', '189.00552368164062 + 231.75344848632812', '49.66218566894531 + 133.19764709472656', '195.63145446777344 + 98.80433654785156', '255.02561950683594 + 224.03890991210938', '114.34735107421875 + 230.1709747314453', '150.42013549804688 + 187.2869415283203', '216.65061950683594 + 236.06689453125', '101.97700500488281 + 195.92062377929688', '68.85855102539062 + 94.32852172851562', '128.5064239501953 + 228.89569091796875', '93.75430297851562 + 184.08285522460938', '39.58808898925781 + 34.40544128417969', '55.772705078125 + 253.20811462402344', '47.77569580078125 + 209.46072387695312', '188.78758239746094 + 159.69422912597656', '141.3863067626953 + 45.26292419433594', '245.9429473876953 + 8.876022338867188', '212.8290252685547 + 192.6466064453125', '33.230010986328125 + 105.86262512207031', '142.36782836914062 + 208.3339385986328', '70.23086547851562 + 226.4280548095703', '219.2831573486328 + 157.7161865234375', '236.3142547607422 + 3.1993255615234375', '50.664581298828125 + 247.45262145996094', '123.88331604003906 + 187.5698699951172', '123.89277648925781 + 92.56607055664062', '210.99661254882812 + 119.12690734863281', '21.215713500976562 + 47.084136962890625', '185.83419799804688 + 19.705825805664062', '97.02552795410156 + 31.511749267578125', '59.45646667480469 + 144.7299346923828', '109.88711547851562 + 92.12374877929688', '89.84257507324219 + 86.84416198730469', '106.5511474609375 + 170.45237731933594', '11.181625366210938 + 127.8538818359375', '90.53189086914062 + 34.16888427734375', '49.71075439453125 + 67.70489501953125', '223.4149169921875 + 98.61961364746094', '75.00010681152344 + 235.10989379882812', '197.6505584716797 + 81.83018493652344', '212.90829467773438 + 121.55268859863281', '73.22758483886719 + 100.48562622070312', '253.97877502441406 + 39.689971923828125', '166.30123901367188 + 215.46578979492188', '59.025726318359375 + 124.17901611328125', '183.15794372558594 + 157.60800170898438', '172.9866180419922 + 79.01200866699219', '55.52703857421875 + 215.51231384277344', '114.33511352539062 + 4.3359832763671875', '212.0589141845703 + 22.884628295898438', '155.32662963867188 + 159.1533966064453', '253.8226318359375 + 184.57496643066406', '111.30946350097656 + 134.96539306640625', '23.995712280273438 + 97.65850830078125', '50.2457275390625 + 30.411300659179688', '76.06648254394531 + 117.72857666015625', '92.75361633300781 + 178.43614196777344', '1.5752410888671875 + 56.66172790527344', '19.254135131835938 + 43.75025939941406', '20.237060546875 + 161.9716033935547', '60.45928955078125 + 158.6143035888672', '149.33460998535156 + 154.07676696777344', '203.74191284179688 + 241.07791137695312', '50.69300842285156 + 133.3126220703125', '22.593597412109375 + 41.439544677734375', '222.0379180908203 + 58.61701965332031', '225.26751708984375 + 245.4508056640625', '237.43692016601562 + 220.80064392089844', '172.5792694091797 + 187.0823974609375', '192.11184692382812 + 67.84532165527344', '137.69468688964844 + 89.41647338867188', '2.6612396240234375 + 55.268646240234375', '81.42872619628906 + 65.11335754394531', '55.81559753417969 + 149.48834228515625', '43.47613525390625 + 138.86749267578125', '226.10504150390625 + 135.5939483642578', '98.97789001464844 + 21.8668212890625', '18.604949951171875 + 35.059356689453125', '138.64100646972656 + 36.148468017578125', '58.71018981933594 + 153.55857849121094', '158.00827026367188 + 26.557022094726562', '43.21826171875 + 241.83265686035156', '245.2205810546875 + 190.72500610351562', '108.48504638671875 + 132.65870666503906', '51.94822692871094 + 17.378936767578125', '190.52276611328125 + 42.99363708496094', '224.83987426757812 + 60.651397705078125', '239.2500762939453 + 98.23175048828125', '198.7770538330078 + 25.895095825195312', '19.076904296875 + 4.107208251953125', '14.57037353515625 + 113.02763366699219', '52.171112060546875 + 119.11482238769531', '206.44557189941406 + 208.44810485839844', '82.05140686035156 + 162.5007781982422', '195.84959411621094 + 195.0447540283203', '27.090255737304688 + 113.56501770019531', '16.74505615234375 + 9.027587890625', '157.71351623535156 + 151.33653259277344', '135.8069610595703 + 202.2183074951172', '207.44285583496094 + 228.5682373046875', '218.94345092773438 + 238.73175048828125', '73.20608520507812 + 31.274490356445312', '243.4857635498047 + 240.30978393554688', '45.09320068359375 + 38.50935363769531', '11.26544189453125 + 36.05790710449219', '184.3229522705078 + 210.0840606689453', '204.4642791748047 + 222.20645141601562', '34.677093505859375 + 141.90286254882812', '246.9725799560547 + 7.748046875', '3.772308349609375 + 156.2530975341797', '226.95220947265625 + 217.2330780029297', '210.87490844726562 + 175.3131561279297', '151.80569458007812 + 227.88394165039062', '164.80050659179688 + 159.7327423095703', '204.22601318359375 + 197.5688018798828', '49.10664367675781 + 191.47418212890625', '252.01528930664062 + 177.70069885253906', '30.39813232421875 + 88.47470092773438', '132.78436279296875 + 68.33140563964844', '29.73565673828125 + 154.85580444335938', '177.53529357910156 + 111.73564147949219', '183.4291229248047 + 32.29270935058594', '47.08282470703125 + 23.459823608398438', '59.8929443359375 + 94.28837585449219', '200.28790283203125 + 213.62301635742188', '16.4686279296875 + 176.5706787109375', '92.18121337890625 + 214.18751525878906', '101.46055603027344 + 105.12521362304688', '33.24629211425781 + 252.02197265625', '84.74029541015625 + 37.530609130859375', '210.1367950439453 + 192.4774627685547', '52.95892333984375 + 123.24092102050781', '67.70158386230469 + 93.32302856445312', '29.415924072265625 + 131.97003173828125', '36.99806213378906 + 187.5148162841797', '10.311492919921875 + 26.040191650390625', '103.59329223632812 + 143.86978149414062', '92.71540832519531 + 224.7398223876953', '182.39212036132812 + 68.06163024902344', '144.2461395263672 + 21.357635498046875', '87.75704956054688 + 40.90913391113281', '94.03579711914062 + 12.831268310546875', '170.7972412109375 + 120.25434875488281', '232.31051635742188 + 249.48233032226562', '36.10466003417969 + 70.46574401855469', '69.02796936035156 + 0.62188720703125', '54.89863586425781 + 157.9712371826172', '81.61366271972656 + 26.784317016601562', '52.88703918457031 + 203.46653747558594', '49.629791259765625 + 75.34654235839844', '234.54095458984375 + 151.25144958496094', '134.73851013183594 + 212.3574981689453', '213.54600524902344 + 235.50485229492188', '10.594223022460938 + 84.85325622558594', '183.151123046875 + 40.9915771484375', '172.7340850830078 + 42.22505187988281', '98.46817016601562 + 88.64747619628906', '80.94093322753906 + 18.160812377929688', '246.16162109375 + 50.98902893066406', '220.15248107910156 + 161.225341796875', '173.1161346435547 + 35.50761413574219', '209.1793212890625 + 55.95466613769531', '239.30276489257812 + 31.506744384765625', '24.612960815429688 + 66.53132629394531', '79.50802612304688 + 30.342269897460938', '188.2239990234375 + 126.85272216796875', '56.38914489746094 + 210.3661346435547', '147.22166442871094 + 111.57672119140625', '60.05931091308594 + 114.77609252929688', '10.937362670898438 + 185.3870391845703', '198.89874267578125 + 2.1246185302734375', '84.23672485351562 + 248.53695678710938', '213.15701293945312 + 160.9683074951172', '40.294921875 + 153.79461669921875', '224.228759765625 + 172.76560974121094', '55.98359680175781 + 54.55369567871094', '78.11210632324219 + 218.89202880859375', '204.54873657226562 + 160.58592224121094', '154.4783935546875 + 195.35293579101562', '149.97308349609375 + 163.09458923339844', '28.523941040039062 + 194.6767120361328', '169.03256225585938 + 161.56446838378906', '32.720733642578125 + 239.46893310546875', '48.9874267578125 + 76.89244079589844', '212.9542694091797 + 69.5264892578125', '68.93580627441406 + 119.33958435058594', '151.3994903564453 + 91.65921020507812', '206.62062072753906 + 113.61634826660156', '109.40951538085938 + 252.75697326660156', '64.77864074707031 + 38.84931945800781', '81.99409484863281 + 88.72528076171875', '96.80509948730469 + 118.70735168457031', '236.1195831298828 + 90.55549621582031', '194.01954650878906 + 154.19351196289062', '221.7501983642578 + 252.60928344726562', '125.12608337402344 + 115.42364501953125', '170.44915771484375 + 38.162445068359375', '132.914794921875 + 154.09805297851562', '208.48275756835938 + 184.63687133789062', '125.459716796875 + 41.73677062988281', '143.0546875 + 3.0790557861328125', '49.89881896972656 + 9.001373291015625', '60.49836730957031 + 19.163742065429688', '144.96786499023438 + 88.06376647949219', '158.4657440185547 + 9.640975952148438', '199.6230010986328 + 108.73974609375', '171.73448181152344 + 14.616531372070312', '195.99664306640625 + 152.06817626953125', '209.32362365722656 + 102.76695251464844', '70.41604614257812 + 187.09808349609375', '55.542083740234375 + 38.80274963378906', '118.77879333496094 + 69.43196105957031', '75.41780090332031 + 178.44638061523438', '171.6194610595703 + 107.13053894042969', '72.61463928222656 + 75.11997985839844', '21.030838012695312 + 237.15179443359375', '195.19300842285156 + 96.12008666992188', '85.734375 + 51.12689208984375', '196.4036407470703 + 255.72535705566406', '251.01968383789062 + 221.89581298828125', '15.898727416992188 + 159.4456787109375', '159.1315460205078 + 72.52926635742188', '90.04965209960938 + 48.81187438964844', '157.19393920898438 + 158.13233947753906', '148.1226348876953 + 120.42263793945312', '100.23306274414062 + 62.81913757324219', '195.30918884277344 + 46.08195495605469', '47.12461853027344 + 129.36404418945312', '55.37760925292969 + 218.21133422851562', '83.35919189453125 + 170.92640686035156', '116.94041442871094 + 22.01220703125', '76.7406005859375 + 200.33389282226562', '87.89390563964844 + 217.5210418701172', '82.96780395507812 + 182.9097137451172', '183.06394958496094 + 66.10560607910156', '186.90878295898438 + 140.73768615722656', '47.17478942871094 + 139.48329162597656', '22.89959716796875 + 206.82357788085938', '123.52294921875 + 214.63034057617188', '2.4514007568359375 + 119.09048461914062', '117.09635925292969 + 69.91288757324219', '27.213775634765625 + 180.0390625', '45.49351501464844 + 12.598831176757812', '210.17092895507812 + 231.0140380859375', '226.96482849121094 + 88.74299621582031', '118.08683776855469 + 18.5079345703125', '155.4911651611328 + 24.662933349609375', '139.8315887451172 + 100.35299682617188', '165.4116973876953 + 146.46148681640625', '37.20957946777344 + 0.0615997314453125', '40.616485595703125 + 248.20687866210938', '185.29962158203125 + 66.53466796875', '58.70701599121094 + 177.86631774902344', '20.094207763671875 + 170.29844665527344', '215.61196899414062 + 21.877288818359375', '132.16766357421875 + 235.86221313476562', '191.895263671875 + 6.5320587158203125', '174.55319213867188 + 63.74476623535156', '139.91586303710938 + 158.5216522216797', '227.17828369140625 + 245.72279357910156', '114.30169677734375 + 44.053070068359375', '83.0557861328125 + 115.86259460449219', '129.9959259033203 + 213.93328857421875', '154.48641967773438 + 21.008468627929688', '250.37405395507812 + 237.7506561279297', '221.29754638671875 + 216.66162109375', '187.45594787597656 + 190.65386962890625', '230.50314331054688 + 103.91691589355469', '5.238800048828125 + 94.20405578613281', '63.320587158203125 + 23.6563720703125', '244.24563598632812 + 214.4546661376953', '205.99639892578125 + 40.20094299316406', '151.5655517578125 + 103.6492919921875', '34.74601745605469 + 56.032867431640625', '218.34658813476562 + 86.83639526367188', '56.61970520019531 + 108.90162658691406', '164.61627197265625 + 43.375030517578125', '19.795669555664062 + 212.63597106933594', '140.11474609375 + 90.21910095214844', '158.24014282226562 + 64.57792663574219', '70.75811767578125 + 241.8102264404297', '131.82615661621094 + 89.64524841308594', '96.5723876953125 + 102.19943237304688', '72.54963684082031 + 198.2329864501953', '218.5953369140625 + 57.2310791015625', '176.8105926513672 + 180.24728393554688', '132.4913787841797 + 142.27130126953125', '19.051177978515625 + 195.17872619628906', '106.44577026367188 + 234.24838256835938', '199.96649169921875 + 27.951080322265625', '105.72222900390625 + 239.5203094482422', '11.085159301757812 + 253.40670776367188', '229.7592315673828 + 0.3006591796875', '239.24891662597656 + 103.91908264160156', '82.45671081542969 + 53.33656311035156', '164.19947814941406 + 91.82489013671875', '142.64010620117188 + 149.7687530517578', '57.62248229980469 + 220.99061584472656', '52.22605895996094 + 143.0258026123047', '98.3995361328125 + 166.97450256347656', '15.837570190429688 + 203.6865692138672', '196.71060180664062 + 128.5267791748047', '207.49183654785156 + 227.27740478515625', '58.87150573730469 + 24.953704833984375', '17.027359008789062 + 254.1472930908203', '70.71427917480469 + 75.80010986328125', '14.4033203125 + 58.51289367675781', '110.79328918457031 + 61.62236022949219', '173.13201904296875 + 223.58116149902344', '27.193389892578125 + 68.20909118652344', '44.954071044921875 + 28.629913330078125', '196.96322631835938 + 167.58265686035156', '186.62374877929688 + 95.51263427734375', '242.82614135742188 + 142.30667114257812', '57.852569580078125 + 93.92704772949219', '50.19218444824219 + 147.20516967773438', '103.0308837890625 + 132.15476989746094', '222.43637084960938 + 244.3817901611328', '43.905548095703125 + 91.60670471191406', '111.93612670898438 + 223.93931579589844', '189.01791381835938 + 173.24932861328125', '117.19563293457031 + 86.62545776367188', '54.96897888183594 + 116.63348388671875', '207.94398498535156 + 164.8081817626953', '241.96876525878906 + 188.19094848632812', '235.33233642578125 + 161.14830017089844', '183.26466369628906 + 188.0339813232422', '108.5157470703125 + 62.3375244140625', '112.696044921875 + 182.29458618164062', '140.85133361816406 + 169.85165405273438', '18.24871826171875 + 152.64927673339844', '91.43850708007812 + 133.47021484375', '32.06922912597656 + 236.81167602539062', '195.7051544189453 + 118.4287109375', '77.62962341308594 + 239.29989624023438', '244.64857482910156 + 159.04566955566406', '75.52108764648438 + 118.94075012207031', '183.4026641845703 + 165.8863983154297', '115.73974609375 + 235.61802673339844', '129.08343505859375 + 136.34002685546875', '183.05636596679688 + 139.89999389648438', '181.8354034423828 + 130.1407012939453', '131.81581115722656 + 205.8181610107422', '5.0101165771484375 + 121.19015502929688', '91.98823547363281 + 142.2158203125', '36.04862976074219 + 80.99659729003906', '160.86314392089844 + 106.77224731445312', '55.259521484375 + 158.2392578125', '239.19618225097656 + 59.9127197265625', '76.68325805664062 + 45.94953918457031', '248.60951232910156 + 7.89251708984375', '176.107421875 + 207.51348876953125', '135.69363403320312 + 8.572830200195312', '170.55934143066406 + 223.20262145996094', '185.886474609375 + 168.68414306640625', '173.8618621826172 + 27.303207397460938', '80.68260192871094 + 201.6739044189453', '142.3014373779297 + 21.125350952148438', '90.55853271484375 + 101.69700622558594', '31.037628173828125 + 82.77851867675781', '87.20625305175781 + 227.65199279785156', '180.64639282226562 + 233.3589324951172', '167.6297607421875 + 21.035415649414062', '190.87957763671875 + 69.1893310546875', '13.57275390625 + 194.8329315185547', '204.57244873046875 + 162.9147186279297', '167.80572509765625 + 253.47483825683594', '185.48153686523438 + 154.0338897705078', '14.604324340820312 + 76.96141052246094', '69.69636535644531 + 252.3858184814453', '82.65093994140625 + 179.7461395263672', '1.2341156005859375 + 252.05784606933594', '101.10324096679688 + 176.56430053710938', '24.924591064453125 + 130.65499877929688', '138.35865783691406 + 214.97927856445312', '166.5135955810547 + 244.72633361816406', '69.94639587402344 + 170.87405395507812', '76.05810546875 + 132.20346069335938', '61.78704833984375 + 17.955307006835938', '12.586257934570312 + 119.07070922851562', '59.97251892089844 + 200.95623779296875', '43.32597351074219 + 204.80874633789062', '199.37142944335938 + 88.51612854003906', '105.53996276855469 + 227.8205108642578', '217.52313232421875 + 47.28733825683594', '210.92967224121094 + 225.31057739257812', '109.67677307128906 + 123.36245727539062', '210.70809936523438 + 151.93174743652344', '197.47332763671875 + 192.18016052246094', '172.6546173095703 + 48.27668762207031', '235.31871032714844 + 14.647308349609375', '51.60868835449219 + 103.42977905273438', '53.502105712890625 + 228.2601318359375', '128.705078125 + 48.968780517578125', '153.6788787841797 + 229.22393798828125', '166.37928771972656 + 165.39111328125', '191.9965057373047 + 244.38009643554688', '97.84007263183594 + 230.78213500976562', '148.0108184814453 + 191.74838256835938', '33.69586181640625 + 69.54095458984375', '90.959716796875 + 37.56123352050781', '23.057327270507812 + 11.66912841796875', '158.2310333251953 + 26.382614135742188', '46.39518737792969 + 65.38851928710938', '82.17999267578125 + 5.053466796875', '210.1229248046875 + 74.7332763671875', '101.43374633789062 + 232.00975036621094', '99.38897705078125 + 76.410888671875', '79.56246948242188 + 172.3681182861328', '250.3535919189453 + 248.15223693847656', '121.21861267089844 + 205.273681640625', '172.9976348876953 + 200.92018127441406', '156.89405822753906 + 64.5894775390625', '108.52738952636719 + 152.73760986328125', '215.9823760986328 + 141.0442352294922', '178.65333557128906 + 173.95083618164062', '168.54812622070312 + 185.4490203857422', '194.32569885253906 + 112.64263916015625', '136.29000854492188 + 39.33454895019531', '175.1662139892578 + 19.729202270507812', '44.69532775878906 + 189.6448211669922', '127.01214599609375 + 76.54057312011719', '38.38121032714844 + 59.06855773925781', '22.157623291015625 + 4.2789154052734375', '188.57608032226562 + 117.93055725097656', '182.10089111328125 + 141.67999267578125', '57.940826416015625 + 120.02093505859375', '41.823455810546875 + 117.43679809570312', '182.21165466308594 + 80.93980407714844', '161.17971801757812 + 180.29605102539062', '82.71875 + 20.691604614257812', '141.1429901123047 + 111.7430419921875', '116.46627807617188 + 78.74749755859375', '54.579559326171875 + 253.69032287597656', '114.83193969726562 + 8.0343017578125', '205.3445281982422 + 38.01124572753906', '110.47190856933594 + 71.16107177734375', '227.68234252929688 + 177.6656494140625', '208.0732879638672 + 33.180908203125', '53.13014221191406 + 52.87406921386719', '159.25469970703125 + 114.91319274902344', '97.874267578125 + 183.73475646972656', '30.273025512695312 + 130.54995727539062', '114.07386779785156 + 108.33494567871094', '133.40872192382812 + 218.93743896484375', '203.75843811035156 + 23.979873657226562', '151.92845153808594 + 116.06199645996094', '213.86680603027344 + 45.68461608886719', '10.518478393554688 + 33.39324951171875', '245.95086669921875 + 97.99089050292969', '14.117324829101562 + 164.03909301757812', '248.980712890625 + 134.082763671875', '170.68060302734375 + 1.267120361328125', '31.280014038085938 + 139.94898986816406', '127.77627563476562 + 90.53765869140625', '237.81829833984375 + 227.69970703125', '19.2459716796875 + 60.38250732421875', '251.8373565673828 + 66.96232604980469', '203.9084930419922 + 15.815414428710938', '132.5388641357422 + 33.039337158203125', '165.86044311523438 + 66.73617553710938', '8.614120483398438 + 214.8930206298828', '172.158935546875 + 230.79234313964844', '68.32614135742188 + 252.16969299316406', '196.78770446777344 + 56.39129638671875', '41.833251953125 + 214.79786682128906', '245.15029907226562 + 186.46092224121094', '186.74908447265625 + 71.47569274902344', '203.78453063964844 + 40.8851318359375', '243.33865356445312 + 163.09478759765625', '205.70791625976562 + 178.96023559570312', '238.26922607421875 + 136.30810546875', '31.926834106445312 + 223.1687774658203', '241.40943908691406 + 36.89619445800781', '78.85432434082031 + 11.731491088867188', '117.27755737304688 + 168.94720458984375', '41.93595886230469 + 183.8762969970703', '57.64854431152344 + 151.50753784179688', '127.00967407226562 + 211.26425170898438', '71.96832275390625 + 22.173599243164062', '29.698348999023438 + 60.69708251953125', '8.69122314453125 + 227.1756134033203', '177.45986938476562 + 182.88229370117188', '141.86358642578125 + 225.2975311279297', '174.4561767578125 + 69.44523620605469', '122.85514831542969 + 138.7266845703125', '244.45953369140625 + 148.7825927734375', '82.41177368164062 + 175.1353759765625', '110.2158203125 + 202.77056884765625', '233.8217315673828 + 122.47628784179688', '182.80751037597656 + 168.9097442626953', '176.71954345703125 + 71.2874755859375', '230.3588409423828 + 231.15895080566406', '0.170806884765625 + 113.57275390625', '231.8411407470703 + 176.18687438964844', '217.5302276611328 + 90.25753784179688', '233.8258056640625 + 249.93553161621094', '155.8921356201172 + 45.8428955078125', '31.536270141601562 + 233.9373779296875', '108.85807800292969 + 117.7657470703125', '239.5707550048828 + 91.55136108398438', '18.108352661132812 + 208.45587158203125', '151.69723510742188 + 78.77557373046875', '60.72892761230469 + 214.2648162841797', '83.807861328125 + 97.43295288085938', '163.49659729003906 + 31.414505004882812', '17.342391967773438 + 130.00067138671875', '169.165283203125 + 4.301483154296875', '14.7764892578125 + 223.99374389648438', '66.53781127929688 + 42.206634521484375', '38.84034729003906 + 36.23353576660156', '13.359054565429688 + 20.393020629882812', '147.0513153076172 + 30.105972290039062', '98.751708984375 + 191.4259796142578', '69.21438598632812 + 29.490692138671875', '190.6548309326172 + 209.51441955566406', '41.71076965332031 + 251.39967346191406', '185.1360626220703 + 52.63078308105469', '122.89082336425781 + 17.057296752929688', '202.52565002441406 + 35.41607666015625', '7.741363525390625 + 140.44100952148438', '213.84397888183594 + 179.5138702392578', '26.781204223632812 + 51.262054443359375', '193.5691680908203 + 136.38795471191406', '99.67442321777344 + 33.541748046875', '225.2529754638672 + 242.94383239746094', '116.48570251464844 + 251.54734802246094', '162.96875 + 13.672088623046875', '76.334228515625 + 165.06954956054688', '184.37486267089844 + 209.58200073242188', '130.1804656982422 + 45.13343811035156', '204.14053344726562 + 1.96514892578125', '167.77383422851562 + 7.2696990966796875', '174.81378173828125 + 177.62094116210938', '113.90205383300781 + 153.5498809814453', '194.6030731201172 + 222.47523498535156', '46.099090576171875 + 248.0589599609375', '179.8017120361328 + 191.7069091796875', '251.4122772216797 + 15.384353637695312', '4.512542724609375 + 115.21476745605469', '11.507308959960938 + 40.451629638671875', '120.037841796875 + 254.24969482421875', '72.79643249511719 + 77.03460693359375', '194.2322235107422 + 172.99888610839844', '216.6654815673828 + 244.99180603027344', '205.79869079589844 + 89.83709716796875', '73.93629455566406 + 211.9585418701172', '95.76483154296875 + 210.1954345703125', '36.47276306152344 + 241.84205627441406', '199.74124145507812 + 41.3463134765625', '201.8975067138672 + 180.2019805908203', '112.73696899414062 + 184.2115936279297', '113.87727355957031 + 18.129135131835938', '199.67591857910156 + 137.02035522460938', '186.3539276123047 + 96.24856567382812', '65.91938781738281 + 6.33935546875', '249.48016357421875 + 165.57479858398438', '76.30592346191406 + 169.1579132080078', '85.01486206054688 + 139.531494140625', '108.83746337890625 + 220.2054901123047', '184.7959747314453 + 188.13247680664062', '25.249099731445312 + 175.36607360839844', '202.8534393310547 + 117.05421447753906', '123.12933349609375 + 48.57017517089844', '139.2932891845703 + 57.03179931640625', '234.1256866455078 + 19.67950439453125', '194.35574340820312 + 225.61424255371094', '81.74386596679688 + 96.84562683105469', '83.40119934082031 + 162.39349365234375', '21.336151123046875 + 204.21112060546875', '90.43949890136719 + 13.225311279296875', '184.52816772460938 + 82.59431457519531', '169.33619689941406 + 55.7376708984375', '121.67680358886719 + 112.49403381347656', '35.51237487792969 + 85.829345703125', '39.130218505859375 + 124.24893188476562', '187.55030822753906 + 110.53993225097656', '205.34896850585938 + 222.22183227539062', '128.92990112304688 + 50.46539306640625', '56.713897705078125 + 37.51268005371094', '240.90406799316406 + 191.70413208007812', '216.17015075683594 + 241.11082458496094', '103.96977233886719 + 198.86688232421875', '233.0475311279297 + 15.26068115234375', '11.24090576171875 + 129.15304565429688', '50.77619934082031 + 198.04827880859375', '174.23455810546875 + 31.122543334960938', '79.41105651855469 + 21.656570434570312', '19.9552001953125 + 219.53709411621094', '30.82830810546875 + 15.737106323242188', '23.41436767578125 + 124.27809143066406', '245.82432556152344 + 232.53692626953125', '78.50503540039062 + 211.32199096679688', '41.38883972167969 + 11.501129150390625', '125.39120483398438 + 64.35687255859375', '135.19540405273438 + 166.72889709472656', '81.38702392578125 + 35.42433166503906', '252.97052001953125 + 41.96711730957031', '88.53170776367188 + 54.13902282714844', '77.34474182128906 + 224.4180145263672', '216.5292510986328 + 9.150802612304688', '23.7615966796875 + 61.72331237792969', '151.20005798339844 + 170.9741668701172', '132.77296447753906 + 226.92857360839844', '161.40408325195312 + 63.021820068359375', '237.2810516357422 + 159.8035430908203', '228.5542449951172 + 108.16596984863281', '183.9536895751953 + 173.55995178222656', '74.71968078613281 + 85.57221984863281', '82.93679809570312 + 152.49688720703125', '8.272933959960938 + 134.83758544921875', '87.31919860839844 + 146.07662963867188', '138.3074951171875 + 111.06321716308594', '94.44564819335938 + 121.61712646484375', '168.6979522705078 + 40.46522521972656', '121.78721618652344 + 182.02618408203125', '123.93804931640625 + 224.24072265625', '175.01072692871094 + 172.93087768554688', '52.318389892578125 + 85.24650573730469', '131.3744659423828 + 187.35142517089844', '236.46688842773438 + 173.7957000732422', '124.82937622070312 + 24.283172607421875', '234.68568420410156 + 238.43211364746094', '217.99258422851562 + 219.53268432617188', '65.65974426269531 + 147.91998291015625', '89.37008666992188 + 171.18704223632812', '49.8507080078125 + 49.059356689453125', '163.49734497070312 + 205.26490783691406', '146.38381958007812 + 254.09268188476562', '131.9322052001953 + 128.1794891357422', '178.39906311035156 + 12.021713256835938', '219.02978515625 + 21.705612182617188', '191.44027709960938 + 200.3968048095703', '66.25868225097656 + 67.25712585449219', '31.659469604492188 + 246.41177368164062', '234.7743682861328 + 104.91439819335938', '217.7090301513672 + 239.01380920410156', '154.1184539794922 + 41.13627624511719', '103.38583374023438 + 163.00918579101562', '1.1004791259765625 + 231.0362091064453', '68.44815063476562 + 191.18858337402344', '210.12913513183594 + 80.75405883789062', '95.4564208984375 + 173.05982971191406', '62.59930419921875 + 4.038726806640625', '234.50355529785156 + 162.6175994873047', '191.7757110595703 + 46.051849365234375', '96.01814270019531 + 220.2411346435547', '59.46043395996094 + 238.83045959472656', '24.737319946289062 + 24.57568359375', '211.22219848632812 + 45.21449279785156', '33.33009338378906 + 89.989013671875', '144.52301025390625 + 239.36093139648438', '243.8123779296875 + 205.6853790283203', '52.77125549316406 + 67.7410888671875', '124.59831237792969 + 133.66558837890625', '76.5526123046875 + 5.4048614501953125', '197.66464233398438 + 166.42613220214844', '52.461944580078125 + 103.96675109863281', '115.86941528320312 + 227.31692504882812', '247.55596923828125 + 70.27275085449219', '42.96153259277344 + 216.4017333984375', '177.69773864746094 + 37.23968505859375', '122.94683837890625 + 158.76467895507812', '42.390655517578125 + 78.42472839355469', '249.1121368408203 + 233.56642150878906', '242.02447509765625 + 226.42965698242188', '149.16419982910156 + 27.170318603515625', '165.0897216796875 + 98.0697021484375', '249.88572692871094 + 36.87158203125', '111.39785766601562 + 171.63482666015625', '240.1055908203125 + 205.16909790039062', '11.970703125 + 194.89854431152344', '70.47087097167969 + 65.56256103515625', '30.723251342773438 + 200.6781005859375', '174.4748077392578 + 11.655410766601562', '175.5879364013672 + 163.95252990722656', '124.26669311523438 + 253.8834686279297', '172.2703857421875 + 243.8520050048828', '89.65972900390625 + 137.2154541015625', '17.2557373046875 + 146.1132354736328', '233.39578247070312 + 212.4639434814453', '221.18505859375 + 84.26776123046875', '39.49076843261719 + 219.0371551513672', '41.75689697265625 + 181.8306121826172', '36.54833984375 + 129.51126098632812', '221.3101806640625 + 183.53280639648438', '7.8416595458984375 + 78.62705993652344', '41.08705139160156 + 126.48472595214844', '48.71235656738281 + 242.7532196044922', '83.04751586914062 + 228.96640014648438', '4.330657958984375 + 187.70375061035156', '169.0170440673828 + 1.186798095703125', '33.28465270996094 + 17.34698486328125', '231.7009735107422 + 104.18170166015625', '115.30912780761719 + 230.773681640625', '130.485595703125 + 237.32293701171875', '122.13282775878906 + 82.14306640625', '134.43569946289062 + 97.65275573730469', '163.77606201171875 + 32.36231994628906', '96.34101867675781 + 65.99549865722656', '20.351715087890625 + 97.52841186523438', '177.739990234375 + 93.25068664550781', '107.73744201660156 + 223.95108032226562', '113.18266296386719 + 196.6728973388672', '188.41285705566406 + 178.20384216308594', '174.2706756591797 + 164.70628356933594', '184.60159301757812 + 123.84689331054688', '105.13510131835938 + 56.49859619140625', '227.54986572265625 + 96.91632080078125', '7.851318359375 + 14.695709228515625', '240.88685607910156 + 98.83319091796875', '21.947341918945312 + 155.48077392578125', '152.48497009277344 + 206.6238555908203', '54.72877502441406 + 112.40037536621094', '131.1221160888672 + 24.800949096679688', '105.99078369140625 + 180.00340270996094', '163.764892578125 + 212.6355438232422', '48.46287536621094 + 112.44735717773438', '79.79396057128906 + 199.62351989746094', '195.8376922607422 + 231.77679443359375', '192.69073486328125 + 169.16293334960938', '149.1576690673828 + 230.11624145507812', '102.65931701660156 + 210.00628662109375', '156.06500244140625 + 141.3603057861328', '0.8596343994140625 + 125.49879455566406', '58.03291320800781 + 252.0196533203125', '130.0513458251953 + 155.8973388671875', '152.6706085205078 + 98.64262390136719', '115.70753479003906 + 59.221527099609375', '40.46287536621094 + 16.817138671875', '226.72982788085938 + 11.878005981445312', '184.61752319335938 + 109.5565185546875', '137.1229705810547 + 100.70271301269531', '20.576858520507812 + 42.2733154296875', '255.82786560058594 + 143.3853759765625', '100.75382995605469 + 177.6179962158203', '85.57914733886719 + 28.936874389648438', '80.27842712402344 + 96.25401306152344', '74.41250610351562 + 219.4324493408203', '127.33094787597656 + 152.8374481201172', '195.39036560058594 + 38.38938903808594', '102.2076416015625 + 156.4615936279297', '212.49884033203125 + 243.0572052001953', '117.79539489746094 + 72.15072631835938', '71.99589538574219 + 145.86746215820312', '0.2847442626953125 + 71.15617370605469', '17.718978881835938 + 140.79263305664062', '205.6295928955078 + 133.64988708496094', '227.122802734375 + 70.30805969238281', '43.38043212890625 + 67.29624938964844', '201.86395263671875 + 170.0609130859375', '215.50271606445312 + 123.10548400878906', '227.65890502929688 + 44.03611755371094', '4.131072998046875 + 14.709228515625', '57.506744384765625 + 209.86907958984375', '104.26170349121094 + 120.26258850097656', '136.2084503173828 + 183.0205535888672', '8.946884155273438 + 217.4453125', '210.55819702148438 + 153.1590118408203', '162.65284729003906 + 78.70207214355469', '239.9849395751953 + 194.341796875', '178.43199157714844 + 120.21125793457031', '24.749832153320312 + 238.13565063476562', '112.15658569335938 + 17.436126708984375', '148.5341033935547 + 154.7235565185547', '196.9243927001953 + 202.5094757080078', '27.171630859375 + 12.826980590820312', '51.75538635253906 + 202.2420654296875', '99.69744873046875 + 227.48001098632812', '254.09762573242188 + 136.0606231689453', '166.75257873535156 + 61.9140625', '1.4449615478515625 + 120.44102478027344', '169.1362762451172 + 235.13525390625', '37.16697692871094 + 170.89224243164062', '255.76829528808594 + 224.52630615234375', '152.27423095703125 + 72.37222290039062', '79.29855346679688 + 248.5399627685547', '181.79623413085938 + 210.93792724609375', '21.239242553710938 + 104.77633666992188', '36.94488525390625 + 89.6817626953125', '115.28431701660156 + 15.902664184570312', '21.349517822265625 + 21.09423828125', '50.722564697265625 + 114.90428161621094', '141.92254638671875 + 154.28701782226562', '210.68621826171875 + 111.61239624023438', '105.88279724121094 + 40.37944030761719', '68.47566223144531 + 125.60984802246094', '91.54087829589844 + 129.24766540527344', '121.87255859375 + 129.33709716796875', '154.07644653320312 + 224.5920867919922', '194.0548858642578 + 63.34690856933594', '253.94049072265625 + 255.0968780517578', '116.75053405761719 + 215.7928924560547', '85.16703796386719 + 236.7991943359375', '105.12040710449219 + 233.19187927246094', '253.27304077148438 + 157.8665313720703', '163.8248291015625 + 11.928070068359375', '162.7131805419922 + 253.0295867919922', '108.99131774902344 + 132.5938720703125', '21.836517333984375 + 214.85519409179688', '84.87246704101562 + 14.665817260742188', '64.86390686035156 + 222.65789794921875', '127.52818298339844 + 39.33586120605469', '90.82183837890625 + 228.10906982421875', '223.7118682861328 + 112.62303161621094', '22.589981079101562 + 124.16099548339844', '184.77163696289062 + 115.17265319824219', '97.02969360351562 + 222.3599853515625', '149.5215606689453 + 203.12367248535156', '140.40325927734375 + 59.26170349121094', '238.96017456054688 + 6.120391845703125', '209.62481689453125 + 183.47305297851562', '12.364669799804688 + 216.73275756835938', '38.45863342285156 + 52.147064208984375', '140.4047088623047 + 10.95489501953125', '225.4853057861328 + 94.99876403808594', '142.04408264160156 + 183.43211364746094', '23.441314697265625 + 118.70877075195312', '72.19956970214844 + 54.922607421875', '66.4381103515625 + 114.28607177734375', '165.7889404296875 + 0.853912353515625', '36.02815246582031 + 192.8455810546875', '64.54290771484375 + 43.30784606933594', '183.49293518066406 + 88.09716796875', '177.10159301757812 + 185.4548797607422', '156.66949462890625 + 92.84983825683594', '124.30549621582031 + 242.86581420898438', '188.48350524902344 + 96.63238525390625', '36.39677429199219 + 126.66096496582031', '236.9799041748047 + 122.58274841308594', '61.160125732421875 + 138.74281311035156', '112.66845703125 + 12.00714111328125', '165.37420654296875 + 215.0826873779297', '43.598968505859375 + 140.4949188232422', '86.89263916015625 + 89.18318176269531', '94.13752746582031 + 133.88584899902344', '212.86427307128906 + 61.2420654296875', '187.8804931640625 + 199.45330810546875', '48.587188720703125 + 116.86479187011719', '243.6750030517578 + 75.70164489746094', '154.1837615966797 + 87.30949401855469', '79.87310791015625 + 241.36573791503906', '202.49441528320312 + 94.25888061523438', '56.60194396972656 + 101.06222534179688', '216.12091064453125 + 50.63005065917969', '118.88760375976562 + 29.670989990234375', '210.08241271972656 + 137.9956512451172', '26.093185424804688 + 226.0001678466797', '165.9798583984375 + 33.478546142578125', '54.555999755859375 + 173.40391540527344', '95.66694641113281 + 23.182815551757812', '21.18603515625 + 229.05941772460938', '224.16871643066406 + 128.30250549316406', '137.65402221679688 + 228.77232360839844', '68.21961975097656 + 202.6222381591797', '119.03318786621094 + 64.36529541015625', '216.7574920654297 + 53.55279541015625', '40.58940124511719 + 44.86354064941406', '178.7977294921875 + 228.2269287109375', '161.21820068359375 + 104.52865600585938', '250.9659423828125 + 207.5580596923828', '92.57887268066406 + 140.39151000976562', '34.3956298828125 + 78.35409545898438', '62.242340087890625 + 81.28097534179688', '121.33753967285156 + 168.28150939941406', '47.04966735839844 + 30.037628173828125', '90.39451599121094 + 144.17584228515625', '146.06320190429688 + 188.6171112060547', '215.9788055419922 + 187.5981903076172', '255.8363494873047 + 118.71653747558594', '49.136993408203125 + 198.09231567382812', '147.7516632080078 + 241.24392700195312', '110.04995727539062 + 105.94132995605469', '163.82090759277344 + 42.783935546875', '205.7187042236328 + 106.15052795410156', '172.2440948486328 + 15.972198486328125', '47.266937255859375 + 88.32408142089844', '147.18785095214844 + 21.595855712890625', '142.88604736328125 + 184.40538024902344', '146.90249633789062 + 149.21353149414062', '114.96484375 + 115.14239501953125', '75.15782165527344 + 203.96746826171875', '227.1469268798828 + 14.487030029296875']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|                                                                                                                      | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:776\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 776\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:738\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 16 at dim 1 (got 15)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 92\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, batch_size, initial_lr, device, use_wandb, project_name)\u001b[0m\n\u001b[1;32m     86\u001b[0m inp_txt \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum1\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum2\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m num1, op, num2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(num1, decoded_operations, num2)\n\u001b[1;32m     88\u001b[0m ]\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINp text is \u001b[39m\u001b[38;5;124m\"\u001b[39m, inp_txt)\n\u001b[0;32m---> 92\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_txt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# print(\"num1 is\", num1)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# print(\"num2 is\", num2 )\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# print(\"op is\", operation)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# print(\"input_ids has shape\", input_ids.shape)\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput ids has shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_ids)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3021\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3020\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3021\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3109\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3104\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3105\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3106\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3107\u001b[0m         )\n\u001b[1;32m   3108\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 3109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3111\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3127\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   3132\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3133\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3151\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3152\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3311\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3302\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3303\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3304\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3308\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3309\u001b[0m )\n\u001b[0;32m-> 3311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3313\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3329\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils.py:892\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m     second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    890\u001b[0m     input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n\u001b[0;32m--> 892\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_prepare_for_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BatchEncoding(batch_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils.py:979\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_prepare_for_model\u001b[0;34m(self, batch_ids_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    968\u001b[0m         batch_outputs[key]\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[1;32m    970\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    971\u001b[0m     batch_outputs,\n\u001b[1;32m    972\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding_strategy\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    976\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[1;32m    977\u001b[0m )\n\u001b[0;32m--> 979\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:240\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    236\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:792\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    788\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    789\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    790\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 792\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    793\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    797\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "train_model(customModel, num_epochs=20, batch_size=1024, initial_lr=1e-4, device='cuda', use_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cv_proj4]",
   "language": "python",
   "name": "conda-env-.conda-cv_proj4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05f5aa7d478e4fc4a766718438cae2de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ea78e20a596498c834fb068380c2a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "201b97b8813d41a4b7661d9f92e098ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "228a14a890c74f81a58ecf89759b2539": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c8b07c27f3242c8884aafe596e6a78d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e528a25513642a1bdc357462a93d6f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca9af9908ea1428fb9e3a7463a53b78b",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_87a5ba1d542b46668992e5d4f07909b7",
      "value": 665
     }
    },
    "3799256f111445e8b19eb4c7da57f16d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3dc783062d1d48339ce06229684cacba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b970dbe014d243299e909c5b954e02c4",
      "max": 548105171,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3799256f111445e8b19eb4c7da57f16d",
      "value": 548105171
     }
    },
    "40d06beaf3184bab820b838f307eced0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1b7aa63a2b54b0da9fbb42cf150224f",
       "IPY_MODEL_2e528a25513642a1bdc357462a93d6f3",
       "IPY_MODEL_a661439821e644c489abdf913dde2f7f"
      ],
      "layout": "IPY_MODEL_228a14a890c74f81a58ecf89759b2539"
     }
    },
    "485bbc552f87497e80485c868face717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d25b4beee8524b5db6c24d791165f9c4",
       "IPY_MODEL_3dc783062d1d48339ce06229684cacba",
       "IPY_MODEL_d91d67a1f0154660adbda90e3a4121ed"
      ],
      "layout": "IPY_MODEL_5909802c97724dcebba8268a0a511677"
     }
    },
    "527f56197cd649288b70c0f5d5510117": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5909802c97724dcebba8268a0a511677": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6db22affb0f74625bb174564a940a4e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87a5ba1d542b46668992e5d4f07909b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a661439821e644c489abdf913dde2f7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05f5aa7d478e4fc4a766718438cae2de",
      "placeholder": "",
      "style": "IPY_MODEL_1ea78e20a596498c834fb068380c2a44",
      "value": "665/665[00:00&lt;00:00,39.4kB/s]"
     }
    },
    "b970dbe014d243299e909c5b954e02c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca9af9908ea1428fb9e3a7463a53b78b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d25b4beee8524b5db6c24d791165f9c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_201b97b8813d41a4b7661d9f92e098ab",
      "placeholder": "",
      "style": "IPY_MODEL_527f56197cd649288b70c0f5d5510117",
      "value": "model.safetensors:100%"
     }
    },
    "d91d67a1f0154660adbda90e3a4121ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c8b07c27f3242c8884aafe596e6a78d",
      "placeholder": "",
      "style": "IPY_MODEL_6db22affb0f74625bb174564a940a4e5",
      "value": "548M/548M[00:02&lt;00:00,241MB/s]"
     }
    },
    "ddf6e3191347473ab221282bc6befa06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1b7aa63a2b54b0da9fbb42cf150224f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddf6e3191347473ab221282bc6befa06",
      "placeholder": "",
      "style": "IPY_MODEL_f1edee125e2145a0aaccdbcebcd5184e",
      "value": "config.json:100%"
     }
    },
    "f1edee125e2145a0aaccdbcebcd5184e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
