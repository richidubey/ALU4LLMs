{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! You have GPU access.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! You have GPU access.\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"CUDA is not available. You do not have GPU access.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O4HLoBN3Swkc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/rdubey36/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model, GPT2Config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Block\n",
    "from typing import Optional, Tuple, Union # Import Optional, Tuple, and Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH8GtPLBdVe5"
   },
   "source": [
    "ALU implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "f8Btv-rvdTqc"
   },
   "outputs": [],
   "source": [
    "class ALU(torch.nn.Module):\n",
    "    def __init__(self, model_dim=768, hidden_dim=512, internal_dim=10, use_output_projection=False):\n",
    "        super(ALU, self).__init__()\n",
    "\n",
    "        # input mlp does model_dim -> hidden_dim -> hidden_dim -> (internal_dim * 2 + 4)\n",
    "        self.input_mlp = nn.Sequential(\n",
    "            nn.Linear(model_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, internal_dim * 2 + 4),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        if use_output_projection:\n",
    "            # output projection does 1 -> internal_dim -> hidden_dim -> model_dim\n",
    "            self.output_projection = nn.Sequential(\n",
    "                nn.Linear(1, internal_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(internal_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, model_dim)\n",
    "            )\n",
    "\n",
    "        self.eps = 1e-8\n",
    "        self.base = torch.tensor([1, 2, 4, 8, 16, 32, 64, 128, 256, 512])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"X-before: \", x.shape)\n",
    "        x = self.input_mlp(x)\n",
    "        a = x[:, :10]\n",
    "        b = x[:, 10:20]\n",
    "        op = x[:, 20:24]\n",
    "        # print(\"X-after: \", x.shape)\n",
    "        # print(\"A: \", a.shape)\n",
    "        # print(\"B: \", b.shape)\n",
    "        # print(\"OP: \", op.shape)\n",
    "        base = torch.tensor([1, 2, 4, 8, 16, 32, 64, 128, 256, 512], device=x.device, dtype=x.dtype)\n",
    "        a = torch.matmul(a, base)\n",
    "        b = torch.matmul(b, base)\n",
    "\n",
    "        op_weights = F.softmax(op, dim=1)  # Shape: (batch_size, 4)\n",
    "\n",
    "        add = a + b\n",
    "        sub = a - b\n",
    "        mul = a * b\n",
    "        div = a / (b + self.eps)\n",
    "\n",
    "        op_outs = torch.stack([add, sub, mul, div], dim=1)  # Shape: (batch_size, 4)\n",
    "        result = torch.sum(op_outs * op_weights, dim=1, keepdim=True)  # Shape: (batch_size, 1)\n",
    "\n",
    "        if hasattr(self, 'output_projection'):\n",
    "            result = self.output_projection(result)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBEfTankdbxj"
   },
   "source": [
    "Standard GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNon2Ds5YkEl",
    "outputId": "8f7a0522-a2b6-4d6b-9a78-aedc3b6823db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig, GPT2Config\n",
    "configuration = GPT2Config()\n",
    "model = GPT2LMHeadModel(configuration)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q-QFXCkb2pC"
   },
   "source": [
    "Modified GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BDbO08rWb6Gt"
   },
   "outputs": [],
   "source": [
    "class CustomGPT2Block(GPT2Block):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.alu = ALU(model_dim=config.n_embd, use_output_projection=True)\n",
    "        self.linear = nn.Linear(config.n_embd, config.n_embd)  # Linear\n",
    "        self.final_projection = nn.Linear(config.n_embd * 2, config.n_embd)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: Optional[Tuple[torch.FloatTensor]],\n",
    "        layer_past: Optional[Tuple[torch.Tensor]] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        use_cache: Optional[bool] = False,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Union[Tuple[torch.Tensor], Optional[Tuple[torch.Tensor, Tuple[torch.FloatTensor, ...]]]]:\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.ln_1(hidden_states)\n",
    "        attn_outputs = self.attn(\n",
    "            hidden_states,\n",
    "            layer_past=layer_past,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        attn_output = attn_outputs[0]  # output_attn: a, present, (attentions)\n",
    "        outputs = attn_outputs[1:]\n",
    "        # residual connection\n",
    "        hidden_states = attn_output + residual\n",
    "\n",
    "        if encoder_hidden_states is not None:\n",
    "            # add one self-attention block for cross-attention\n",
    "            if not hasattr(self, \"crossattention\"):\n",
    "                raise ValueError(\n",
    "                    f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with \"\n",
    "                    \"cross-attention layers by setting `config.add_cross_attention=True`\"\n",
    "                )\n",
    "            residual = hidden_states\n",
    "            hidden_states = self.ln_cross_attn(hidden_states)\n",
    "            cross_attn_outputs = self.crossattention(\n",
    "                hidden_states,\n",
    "                attention_mask=attention_mask,\n",
    "                head_mask=head_mask,\n",
    "                encoder_hidden_states=encoder_hidden_states,\n",
    "                encoder_attention_mask=encoder_attention_mask,\n",
    "                output_attentions=output_attentions,\n",
    "            )\n",
    "            attn_output = cross_attn_outputs[0]\n",
    "            # residual connection\n",
    "            hidden_states = residual + attn_output\n",
    "            outputs = outputs + cross_attn_outputs[2:]  # add cross attentions if we output attention weights\n",
    "\n",
    "        alu_hidden_states = self.linear(hidden_states) # NEW CODE: using a linear layer to transform the current hidden_state for alu computation\n",
    "        summed_alu_hidden_states = alu_hidden_states.sum(dim=1)  # NEW CODE: summing across dimension 1 (sequence length) Shape: [batch_size, embedding_dim]\n",
    "        alu_output = self.alu(summed_alu_hidden_states)     # NEW CODE: calling the ALU using the hidden_states\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.ln_2(hidden_states)\n",
    "        feed_forward_hidden_states = self.mlp(hidden_states)\n",
    "        # residual connection\n",
    "        hidden_states = residual + feed_forward_hidden_states\n",
    "        hidden_states = torch.cat([hidden_states, alu_output.unsqueeze(1).expand(-1, hidden_states.size(1), -1)], dim=-1) # NEW CODE: concatenating the ALU output to the hidden states\n",
    "        hidden_states = self.final_projection(hidden_states)  # NEW CODE: projecting the hidden_state to the required dimension\n",
    "        outputs = (hidden_states,) + outputs\n",
    "\n",
    "        if use_cache:\n",
    "            outputs = (hidden_states,) + outputs\n",
    "        else:\n",
    "            outputs = (hidden_states,) + outputs[1:]\n",
    "\n",
    "        return outputs  # hidden_states, present, (attentions, cross_attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z_5hmrIkcBv0"
   },
   "outputs": [],
   "source": [
    "class CustomGPT2Model(GPT2LMHeadModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        num_layers = len(self.transformer.h)\n",
    "        for i in range(num_layers - 3, num_layers):\n",
    "            self.transformer.h[i] = CustomGPT2Block(config)\n",
    "        \n",
    "        #Add LM head\n",
    "        #self.lm_head = torch.nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, input_ids=None, past_key_values=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, encoder_hidden_states=None, encoder_attention_mask=None, labels=None, use_cache=None, output_attentions=None, output_hidden_states=None, return_dict=None):\n",
    "        \n",
    "        return super().forward(\n",
    "            input_ids,\n",
    "            past_key_values, \n",
    "            attention_mask, \n",
    "            token_type_ids, \n",
    "            position_ids, \n",
    "            head_mask, \n",
    "            inputs_embeds, \n",
    "            encoder_hidden_states, \n",
    "            encoder_attention_mask, \n",
    "            labels,\n",
    "            use_cache, \n",
    "            output_attentions, \n",
    "            output_hidden_states, \n",
    "            return_dict)\n",
    "    \n",
    "        # hidden_states = outputs.last_hidden_state\n",
    "        # logits = self.lm_head(hidden_states)\n",
    "\n",
    "        # return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y--X2HVdcJL7",
    "outputId": "c1eecea2-a4c7-4a03-d66f-d49c99143f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomGPT2Model(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-8): 9 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9-11): 3 x CustomGPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (alu): ALU(\n",
      "          (input_mlp): Sequential(\n",
      "            (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.01)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.01)\n",
      "            (4): Linear(in_features=512, out_features=24, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "          (output_projection): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=10, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=10, out_features=512, bias=True)\n",
      "            (3): ReLU()\n",
      "            (4): Linear(in_features=512, out_features=768, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (final_projection): Linear(in_features=1536, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model2 = CustomGPT2Model(configuration)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYcll4KAcgcx"
   },
   "source": [
    "Later to load the weights (Need to verify this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379,
     "referenced_widgets": [
      "40d06beaf3184bab820b838f307eced0",
      "f1b7aa63a2b54b0da9fbb42cf150224f",
      "2e528a25513642a1bdc357462a93d6f3",
      "a661439821e644c489abdf913dde2f7f",
      "228a14a890c74f81a58ecf89759b2539",
      "ddf6e3191347473ab221282bc6befa06",
      "f1edee125e2145a0aaccdbcebcd5184e",
      "ca9af9908ea1428fb9e3a7463a53b78b",
      "87a5ba1d542b46668992e5d4f07909b7",
      "05f5aa7d478e4fc4a766718438cae2de",
      "1ea78e20a596498c834fb068380c2a44",
      "485bbc552f87497e80485c868face717",
      "d25b4beee8524b5db6c24d791165f9c4",
      "3dc783062d1d48339ce06229684cacba",
      "d91d67a1f0154660adbda90e3a4121ed",
      "5909802c97724dcebba8268a0a511677",
      "201b97b8813d41a4b7661d9f92e098ab",
      "527f56197cd649288b70c0f5d5510117",
      "b970dbe014d243299e909c5b954e02c4",
      "3799256f111445e8b19eb4c7da57f16d",
      "2c8b07c27f3242c8884aafe596e6a78d",
      "6db22affb0f74625bb174564a940a4e5"
     ]
    },
    "id": "MsEAWHjxcikD",
    "outputId": "8e510c21-3850-4f87-beac-85f6bb7af6e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight False\n",
      "transformer.wpe.weight False\n",
      "transformer.h.0.ln_1.weight False\n",
      "transformer.h.0.ln_1.bias False\n",
      "transformer.h.0.attn.c_attn.weight False\n",
      "transformer.h.0.attn.c_attn.bias False\n",
      "transformer.h.0.attn.c_proj.weight False\n",
      "transformer.h.0.attn.c_proj.bias False\n",
      "transformer.h.0.ln_2.weight False\n",
      "transformer.h.0.ln_2.bias False\n",
      "transformer.h.0.mlp.c_fc.weight False\n",
      "transformer.h.0.mlp.c_fc.bias False\n",
      "transformer.h.0.mlp.c_proj.weight False\n",
      "transformer.h.0.mlp.c_proj.bias False\n",
      "transformer.h.1.ln_1.weight False\n",
      "transformer.h.1.ln_1.bias False\n",
      "transformer.h.1.attn.c_attn.weight False\n",
      "transformer.h.1.attn.c_attn.bias False\n",
      "transformer.h.1.attn.c_proj.weight False\n",
      "transformer.h.1.attn.c_proj.bias False\n",
      "transformer.h.1.ln_2.weight False\n",
      "transformer.h.1.ln_2.bias False\n",
      "transformer.h.1.mlp.c_fc.weight False\n",
      "transformer.h.1.mlp.c_fc.bias False\n",
      "transformer.h.1.mlp.c_proj.weight False\n",
      "transformer.h.1.mlp.c_proj.bias False\n",
      "transformer.h.2.ln_1.weight False\n",
      "transformer.h.2.ln_1.bias False\n",
      "transformer.h.2.attn.c_attn.weight False\n",
      "transformer.h.2.attn.c_attn.bias False\n",
      "transformer.h.2.attn.c_proj.weight False\n",
      "transformer.h.2.attn.c_proj.bias False\n",
      "transformer.h.2.ln_2.weight False\n",
      "transformer.h.2.ln_2.bias False\n",
      "transformer.h.2.mlp.c_fc.weight False\n",
      "transformer.h.2.mlp.c_fc.bias False\n",
      "transformer.h.2.mlp.c_proj.weight False\n",
      "transformer.h.2.mlp.c_proj.bias False\n",
      "transformer.h.3.ln_1.weight False\n",
      "transformer.h.3.ln_1.bias False\n",
      "transformer.h.3.attn.c_attn.weight False\n",
      "transformer.h.3.attn.c_attn.bias False\n",
      "transformer.h.3.attn.c_proj.weight False\n",
      "transformer.h.3.attn.c_proj.bias False\n",
      "transformer.h.3.ln_2.weight False\n",
      "transformer.h.3.ln_2.bias False\n",
      "transformer.h.3.mlp.c_fc.weight False\n",
      "transformer.h.3.mlp.c_fc.bias False\n",
      "transformer.h.3.mlp.c_proj.weight False\n",
      "transformer.h.3.mlp.c_proj.bias False\n",
      "transformer.h.4.ln_1.weight False\n",
      "transformer.h.4.ln_1.bias False\n",
      "transformer.h.4.attn.c_attn.weight False\n",
      "transformer.h.4.attn.c_attn.bias False\n",
      "transformer.h.4.attn.c_proj.weight False\n",
      "transformer.h.4.attn.c_proj.bias False\n",
      "transformer.h.4.ln_2.weight False\n",
      "transformer.h.4.ln_2.bias False\n",
      "transformer.h.4.mlp.c_fc.weight False\n",
      "transformer.h.4.mlp.c_fc.bias False\n",
      "transformer.h.4.mlp.c_proj.weight False\n",
      "transformer.h.4.mlp.c_proj.bias False\n",
      "transformer.h.5.ln_1.weight False\n",
      "transformer.h.5.ln_1.bias False\n",
      "transformer.h.5.attn.c_attn.weight False\n",
      "transformer.h.5.attn.c_attn.bias False\n",
      "transformer.h.5.attn.c_proj.weight False\n",
      "transformer.h.5.attn.c_proj.bias False\n",
      "transformer.h.5.ln_2.weight False\n",
      "transformer.h.5.ln_2.bias False\n",
      "transformer.h.5.mlp.c_fc.weight False\n",
      "transformer.h.5.mlp.c_fc.bias False\n",
      "transformer.h.5.mlp.c_proj.weight False\n",
      "transformer.h.5.mlp.c_proj.bias False\n",
      "transformer.h.6.ln_1.weight False\n",
      "transformer.h.6.ln_1.bias False\n",
      "transformer.h.6.attn.c_attn.weight False\n",
      "transformer.h.6.attn.c_attn.bias False\n",
      "transformer.h.6.attn.c_proj.weight False\n",
      "transformer.h.6.attn.c_proj.bias False\n",
      "transformer.h.6.ln_2.weight False\n",
      "transformer.h.6.ln_2.bias False\n",
      "transformer.h.6.mlp.c_fc.weight False\n",
      "transformer.h.6.mlp.c_fc.bias False\n",
      "transformer.h.6.mlp.c_proj.weight False\n",
      "transformer.h.6.mlp.c_proj.bias False\n",
      "transformer.h.7.ln_1.weight False\n",
      "transformer.h.7.ln_1.bias False\n",
      "transformer.h.7.attn.c_attn.weight False\n",
      "transformer.h.7.attn.c_attn.bias False\n",
      "transformer.h.7.attn.c_proj.weight False\n",
      "transformer.h.7.attn.c_proj.bias False\n",
      "transformer.h.7.ln_2.weight False\n",
      "transformer.h.7.ln_2.bias False\n",
      "transformer.h.7.mlp.c_fc.weight False\n",
      "transformer.h.7.mlp.c_fc.bias False\n",
      "transformer.h.7.mlp.c_proj.weight False\n",
      "transformer.h.7.mlp.c_proj.bias False\n",
      "transformer.h.8.ln_1.weight False\n",
      "transformer.h.8.ln_1.bias False\n",
      "transformer.h.8.attn.c_attn.weight False\n",
      "transformer.h.8.attn.c_attn.bias False\n",
      "transformer.h.8.attn.c_proj.weight False\n",
      "transformer.h.8.attn.c_proj.bias False\n",
      "transformer.h.8.ln_2.weight False\n",
      "transformer.h.8.ln_2.bias False\n",
      "transformer.h.8.mlp.c_fc.weight False\n",
      "transformer.h.8.mlp.c_fc.bias False\n",
      "transformer.h.8.mlp.c_proj.weight False\n",
      "transformer.h.8.mlp.c_proj.bias False\n",
      "transformer.h.9.ln_1.weight True\n",
      "transformer.h.9.ln_1.bias True\n",
      "transformer.h.9.attn.c_attn.weight True\n",
      "transformer.h.9.attn.c_attn.bias True\n",
      "transformer.h.9.attn.c_proj.weight True\n",
      "transformer.h.9.attn.c_proj.bias True\n",
      "transformer.h.9.ln_2.weight True\n",
      "transformer.h.9.ln_2.bias True\n",
      "transformer.h.9.mlp.c_fc.weight True\n",
      "transformer.h.9.mlp.c_fc.bias True\n",
      "transformer.h.9.mlp.c_proj.weight True\n",
      "transformer.h.9.mlp.c_proj.bias True\n",
      "transformer.h.9.alu.input_mlp.0.weight True\n",
      "transformer.h.9.alu.input_mlp.0.bias True\n",
      "transformer.h.9.alu.input_mlp.2.weight True\n",
      "transformer.h.9.alu.input_mlp.2.bias True\n",
      "transformer.h.9.alu.input_mlp.4.weight True\n",
      "transformer.h.9.alu.input_mlp.4.bias True\n",
      "transformer.h.9.alu.output_projection.0.weight True\n",
      "transformer.h.9.alu.output_projection.0.bias True\n",
      "transformer.h.9.alu.output_projection.2.weight True\n",
      "transformer.h.9.alu.output_projection.2.bias True\n",
      "transformer.h.9.alu.output_projection.4.weight True\n",
      "transformer.h.9.alu.output_projection.4.bias True\n",
      "transformer.h.9.linear.weight True\n",
      "transformer.h.9.linear.bias True\n",
      "transformer.h.9.final_projection.weight True\n",
      "transformer.h.9.final_projection.bias True\n",
      "transformer.h.10.ln_1.weight True\n",
      "transformer.h.10.ln_1.bias True\n",
      "transformer.h.10.attn.c_attn.weight True\n",
      "transformer.h.10.attn.c_attn.bias True\n",
      "transformer.h.10.attn.c_proj.weight True\n",
      "transformer.h.10.attn.c_proj.bias True\n",
      "transformer.h.10.ln_2.weight True\n",
      "transformer.h.10.ln_2.bias True\n",
      "transformer.h.10.mlp.c_fc.weight True\n",
      "transformer.h.10.mlp.c_fc.bias True\n",
      "transformer.h.10.mlp.c_proj.weight True\n",
      "transformer.h.10.mlp.c_proj.bias True\n",
      "transformer.h.10.alu.input_mlp.0.weight True\n",
      "transformer.h.10.alu.input_mlp.0.bias True\n",
      "transformer.h.10.alu.input_mlp.2.weight True\n",
      "transformer.h.10.alu.input_mlp.2.bias True\n",
      "transformer.h.10.alu.input_mlp.4.weight True\n",
      "transformer.h.10.alu.input_mlp.4.bias True\n",
      "transformer.h.10.alu.output_projection.0.weight True\n",
      "transformer.h.10.alu.output_projection.0.bias True\n",
      "transformer.h.10.alu.output_projection.2.weight True\n",
      "transformer.h.10.alu.output_projection.2.bias True\n",
      "transformer.h.10.alu.output_projection.4.weight True\n",
      "transformer.h.10.alu.output_projection.4.bias True\n",
      "transformer.h.10.linear.weight True\n",
      "transformer.h.10.linear.bias True\n",
      "transformer.h.10.final_projection.weight True\n",
      "transformer.h.10.final_projection.bias True\n",
      "transformer.h.11.ln_1.weight True\n",
      "transformer.h.11.ln_1.bias True\n",
      "transformer.h.11.attn.c_attn.weight True\n",
      "transformer.h.11.attn.c_attn.bias True\n",
      "transformer.h.11.attn.c_proj.weight True\n",
      "transformer.h.11.attn.c_proj.bias True\n",
      "transformer.h.11.ln_2.weight True\n",
      "transformer.h.11.ln_2.bias True\n",
      "transformer.h.11.mlp.c_fc.weight True\n",
      "transformer.h.11.mlp.c_fc.bias True\n",
      "transformer.h.11.mlp.c_proj.weight True\n",
      "transformer.h.11.mlp.c_proj.bias True\n",
      "transformer.h.11.alu.input_mlp.0.weight True\n",
      "transformer.h.11.alu.input_mlp.0.bias True\n",
      "transformer.h.11.alu.input_mlp.2.weight True\n",
      "transformer.h.11.alu.input_mlp.2.bias True\n",
      "transformer.h.11.alu.input_mlp.4.weight True\n",
      "transformer.h.11.alu.input_mlp.4.bias True\n",
      "transformer.h.11.alu.output_projection.0.weight True\n",
      "transformer.h.11.alu.output_projection.0.bias True\n",
      "transformer.h.11.alu.output_projection.2.weight True\n",
      "transformer.h.11.alu.output_projection.2.bias True\n",
      "transformer.h.11.alu.output_projection.4.weight True\n",
      "transformer.h.11.alu.output_projection.4.bias True\n",
      "transformer.h.11.linear.weight True\n",
      "transformer.h.11.linear.bias True\n",
      "transformer.h.11.final_projection.weight True\n",
      "transformer.h.11.final_projection.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['transformer.wte.weight', 'transformer.wpe.weight', 'transformer.h.0.ln_1.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.0.attn.c_attn.weight', 'transformer.h.0.attn.c_attn.bias', 'transformer.h.0.attn.c_proj.weight', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.2.attn.c_attn.weight', 'transformer.h.2.attn.c_attn.bias', 'transformer.h.2.attn.c_proj.weight', 'transformer.h.2.attn.c_proj.bias', 'transformer.h.2.ln_2.weight', 'transformer.h.2.ln_2.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.3.attn.c_attn.weight', 'transformer.h.3.attn.c_attn.bias', 'transformer.h.3.attn.c_proj.weight', 'transformer.h.3.attn.c_proj.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.4.ln_1.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.4.attn.c_attn.weight', 'transformer.h.4.attn.c_attn.bias', 'transformer.h.4.attn.c_proj.weight', 'transformer.h.4.attn.c_proj.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.5.attn.c_attn.weight', 'transformer.h.5.attn.c_attn.bias', 'transformer.h.5.attn.c_proj.weight', 'transformer.h.5.attn.c_proj.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.6.ln_1.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.6.attn.c_attn.weight', 'transformer.h.6.attn.c_attn.bias', 'transformer.h.6.attn.c_proj.weight', 'transformer.h.6.attn.c_proj.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.6.ln_2.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.7.attn.c_attn.weight', 'transformer.h.7.attn.c_attn.bias', 'transformer.h.7.attn.c_proj.weight', 'transformer.h.7.attn.c_proj.bias', 'transformer.h.7.ln_2.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.8.ln_1.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.8.attn.c_attn.weight', 'transformer.h.8.attn.c_attn.bias', 'transformer.h.8.attn.c_proj.weight', 'transformer.h.8.attn.c_proj.bias', 'transformer.h.8.ln_2.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.9.attn.c_attn.weight', 'transformer.h.9.attn.c_attn.bias', 'transformer.h.9.attn.c_proj.weight', 'transformer.h.9.attn.c_proj.bias', 'transformer.h.9.ln_2.weight', 'transformer.h.9.ln_2.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.9.alu.input_mlp.0.weight', 'transformer.h.9.alu.input_mlp.0.bias', 'transformer.h.9.alu.input_mlp.2.weight', 'transformer.h.9.alu.input_mlp.2.bias', 'transformer.h.9.alu.input_mlp.4.weight', 'transformer.h.9.alu.input_mlp.4.bias', 'transformer.h.9.alu.output_projection.0.weight', 'transformer.h.9.alu.output_projection.0.bias', 'transformer.h.9.alu.output_projection.2.weight', 'transformer.h.9.alu.output_projection.2.bias', 'transformer.h.9.alu.output_projection.4.weight', 'transformer.h.9.alu.output_projection.4.bias', 'transformer.h.9.linear.weight', 'transformer.h.9.linear.bias', 'transformer.h.9.final_projection.weight', 'transformer.h.9.final_projection.bias', 'transformer.h.10.ln_1.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.10.attn.c_attn.weight', 'transformer.h.10.attn.c_attn.bias', 'transformer.h.10.attn.c_proj.weight', 'transformer.h.10.attn.c_proj.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.10.alu.input_mlp.0.weight', 'transformer.h.10.alu.input_mlp.0.bias', 'transformer.h.10.alu.input_mlp.2.weight', 'transformer.h.10.alu.input_mlp.2.bias', 'transformer.h.10.alu.input_mlp.4.weight', 'transformer.h.10.alu.input_mlp.4.bias', 'transformer.h.10.alu.output_projection.0.weight', 'transformer.h.10.alu.output_projection.0.bias', 'transformer.h.10.alu.output_projection.2.weight', 'transformer.h.10.alu.output_projection.2.bias', 'transformer.h.10.alu.output_projection.4.weight', 'transformer.h.10.alu.output_projection.4.bias', 'transformer.h.10.linear.weight', 'transformer.h.10.linear.bias', 'transformer.h.10.final_projection.weight', 'transformer.h.10.final_projection.bias', 'transformer.h.11.ln_1.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.11.attn.c_attn.weight', 'transformer.h.11.attn.c_attn.bias', 'transformer.h.11.attn.c_proj.weight', 'transformer.h.11.attn.c_proj.bias', 'transformer.h.11.ln_2.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.11.alu.input_mlp.0.weight', 'transformer.h.11.alu.input_mlp.0.bias', 'transformer.h.11.alu.input_mlp.2.weight', 'transformer.h.11.alu.input_mlp.2.bias', 'transformer.h.11.alu.input_mlp.4.weight', 'transformer.h.11.alu.input_mlp.4.bias', 'transformer.h.11.alu.output_projection.0.weight', 'transformer.h.11.alu.output_projection.0.bias', 'transformer.h.11.alu.output_projection.2.weight', 'transformer.h.11.alu.output_projection.2.bias', 'transformer.h.11.alu.output_projection.4.weight', 'transformer.h.11.alu.output_projection.4.bias', 'transformer.h.11.linear.weight', 'transformer.h.11.linear.bias', 'transformer.h.11.final_projection.weight', 'transformer.h.11.final_projection.bias', 'transformer.ln_f.weight', 'transformer.ln_f.bias', 'lm_head.weight'], unexpected_keys=['wte.weight', 'wpe.weight', 'h.0.ln_1.weight', 'h.0.ln_1.bias', 'h.0.attn.c_attn.weight', 'h.0.attn.c_attn.bias', 'h.0.attn.c_proj.weight', 'h.0.attn.c_proj.bias', 'h.0.ln_2.weight', 'h.0.ln_2.bias', 'h.0.mlp.c_fc.weight', 'h.0.mlp.c_fc.bias', 'h.0.mlp.c_proj.weight', 'h.0.mlp.c_proj.bias', 'h.1.ln_1.weight', 'h.1.ln_1.bias', 'h.1.attn.c_attn.weight', 'h.1.attn.c_attn.bias', 'h.1.attn.c_proj.weight', 'h.1.attn.c_proj.bias', 'h.1.ln_2.weight', 'h.1.ln_2.bias', 'h.1.mlp.c_fc.weight', 'h.1.mlp.c_fc.bias', 'h.1.mlp.c_proj.weight', 'h.1.mlp.c_proj.bias', 'h.2.ln_1.weight', 'h.2.ln_1.bias', 'h.2.attn.c_attn.weight', 'h.2.attn.c_attn.bias', 'h.2.attn.c_proj.weight', 'h.2.attn.c_proj.bias', 'h.2.ln_2.weight', 'h.2.ln_2.bias', 'h.2.mlp.c_fc.weight', 'h.2.mlp.c_fc.bias', 'h.2.mlp.c_proj.weight', 'h.2.mlp.c_proj.bias', 'h.3.ln_1.weight', 'h.3.ln_1.bias', 'h.3.attn.c_attn.weight', 'h.3.attn.c_attn.bias', 'h.3.attn.c_proj.weight', 'h.3.attn.c_proj.bias', 'h.3.ln_2.weight', 'h.3.ln_2.bias', 'h.3.mlp.c_fc.weight', 'h.3.mlp.c_fc.bias', 'h.3.mlp.c_proj.weight', 'h.3.mlp.c_proj.bias', 'h.4.ln_1.weight', 'h.4.ln_1.bias', 'h.4.attn.c_attn.weight', 'h.4.attn.c_attn.bias', 'h.4.attn.c_proj.weight', 'h.4.attn.c_proj.bias', 'h.4.ln_2.weight', 'h.4.ln_2.bias', 'h.4.mlp.c_fc.weight', 'h.4.mlp.c_fc.bias', 'h.4.mlp.c_proj.weight', 'h.4.mlp.c_proj.bias', 'h.5.ln_1.weight', 'h.5.ln_1.bias', 'h.5.attn.c_attn.weight', 'h.5.attn.c_attn.bias', 'h.5.attn.c_proj.weight', 'h.5.attn.c_proj.bias', 'h.5.ln_2.weight', 'h.5.ln_2.bias', 'h.5.mlp.c_fc.weight', 'h.5.mlp.c_fc.bias', 'h.5.mlp.c_proj.weight', 'h.5.mlp.c_proj.bias', 'h.6.ln_1.weight', 'h.6.ln_1.bias', 'h.6.attn.c_attn.weight', 'h.6.attn.c_attn.bias', 'h.6.attn.c_proj.weight', 'h.6.attn.c_proj.bias', 'h.6.ln_2.weight', 'h.6.ln_2.bias', 'h.6.mlp.c_fc.weight', 'h.6.mlp.c_fc.bias', 'h.6.mlp.c_proj.weight', 'h.6.mlp.c_proj.bias', 'h.7.ln_1.weight', 'h.7.ln_1.bias', 'h.7.attn.c_attn.weight', 'h.7.attn.c_attn.bias', 'h.7.attn.c_proj.weight', 'h.7.attn.c_proj.bias', 'h.7.ln_2.weight', 'h.7.ln_2.bias', 'h.7.mlp.c_fc.weight', 'h.7.mlp.c_fc.bias', 'h.7.mlp.c_proj.weight', 'h.7.mlp.c_proj.bias', 'h.8.ln_1.weight', 'h.8.ln_1.bias', 'h.8.attn.c_attn.weight', 'h.8.attn.c_attn.bias', 'h.8.attn.c_proj.weight', 'h.8.attn.c_proj.bias', 'h.8.ln_2.weight', 'h.8.ln_2.bias', 'h.8.mlp.c_fc.weight', 'h.8.mlp.c_fc.bias', 'h.8.mlp.c_proj.weight', 'h.8.mlp.c_proj.bias', 'h.9.ln_1.weight', 'h.9.ln_1.bias', 'h.9.attn.c_attn.weight', 'h.9.attn.c_attn.bias', 'h.9.attn.c_proj.weight', 'h.9.attn.c_proj.bias', 'h.9.ln_2.weight', 'h.9.ln_2.bias', 'h.9.mlp.c_fc.weight', 'h.9.mlp.c_fc.bias', 'h.9.mlp.c_proj.weight', 'h.9.mlp.c_proj.bias', 'h.10.ln_1.weight', 'h.10.ln_1.bias', 'h.10.attn.c_attn.weight', 'h.10.attn.c_attn.bias', 'h.10.attn.c_proj.weight', 'h.10.attn.c_proj.bias', 'h.10.ln_2.weight', 'h.10.ln_2.bias', 'h.10.mlp.c_fc.weight', 'h.10.mlp.c_fc.bias', 'h.10.mlp.c_proj.weight', 'h.10.mlp.c_proj.bias', 'h.11.ln_1.weight', 'h.11.ln_1.bias', 'h.11.attn.c_attn.weight', 'h.11.attn.c_attn.bias', 'h.11.attn.c_proj.weight', 'h.11.attn.c_proj.bias', 'h.11.ln_2.weight', 'h.11.ln_2.bias', 'h.11.mlp.c_fc.weight', 'h.11.mlp.c_fc.bias', 'h.11.mlp.c_proj.weight', 'h.11.mlp.c_proj.bias', 'ln_f.weight', 'ln_f.bias'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = GPT2Config.from_pretrained('gpt2')\n",
    "customModel = CustomGPT2Model(config)\n",
    "\n",
    "# for name, param in model2.named_parameters():\n",
    "#     print(name, param.requires_grad)\n",
    "\n",
    "for param in customModel.transformer.wte.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in customModel.transformer.wpe.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in customModel.transformer.h.named_parameters():\n",
    "    # print(\"Name is\",int(name.split('.')[0]))\n",
    "    if int(name.split('.')[0])<9:\n",
    "        param.requires_grad = False\n",
    "    # print(name, param.requires_grad)\n",
    "\n",
    "for name, param in customModel.named_parameters():\n",
    "     print(name, param.requires_grad)\n",
    "\n",
    "\n",
    "# If you want to load pre-trained weights:\n",
    "state_dict = GPT2Model.from_pretrained('gpt2').state_dict()\n",
    "customModel.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomGPT2Model(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-8): 9 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9-11): 3 x CustomGPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (alu): ALU(\n",
       "          (input_mlp): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.01)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.01)\n",
       "            (4): Linear(in_features=512, out_features=24, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.01)\n",
       "          )\n",
       "          (output_projection): Sequential(\n",
       "            (0): Linear(in_features=1, out_features=10, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=10, out_features=512, bias=True)\n",
       "            (3): ReLU()\n",
       "            (4): Linear(in_features=512, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (final_projection): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: Once upon a time,uk\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Config, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "customModel.eval()\n",
    "input_text = \"Once upon a time,\"\n",
    "\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")[\"input_ids\"].to(customModel.device)\n",
    "#print(\"Device of input ids is\", input_ids.device)\n",
    "# with torch.no_grad():\n",
    "#     logits = customModel(input_ids=input_ids)\n",
    "\n",
    "output_ids = customModel.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=6,  # Maximum length of generated text\n",
    "    num_return_sequences=1,  # Number of sequences to generate\n",
    "    do_sample=True,  # Enable sampling\n",
    "    top_k=50,  # Use top-k sampling\n",
    "    temperature=0.7,  # Sampling temperature\n",
    ")\n",
    "\n",
    "predicted_ids = output_ids\n",
    "\n",
    "generated_text = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataset to finetune\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "\n",
    "class ArithmeticDataset(IterableDataset):\n",
    "    def __init__(self, min_val=0, max_val=256):\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "        \n",
    "        self.operations = {\n",
    "            0: lambda x, y: x + y,    # addition\n",
    "            1: lambda x, y: x - y,    # subtraction\n",
    "            2: lambda x, y: x * y,    # multiplication\n",
    "            3: lambda x, y: x / (y + 1e-8)  # division\n",
    "        }\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            # Generate random numbers\n",
    "            num1 = torch.rand(1) * (self.max_val - self.min_val) + self.min_val\n",
    "            num2 = torch.rand(1) * (self.max_val - self.min_val) + self.min_val\n",
    "            \n",
    "            # Generate random operations\n",
    "            op_idx = torch.tensor([0]) # torch.randint(0, 4, (1,))\n",
    "            operation = F.one_hot(op_idx, num_classes=4).float()\n",
    "            \n",
    "            # Calculate targets\n",
    "            target = self.operations[op_idx.item()](num1, num2)            \n",
    "            \n",
    "            yield num1, num2, operation.squeeze(0), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([26.5930]), tensor([32.3837]), tensor([1., 0., 0., 0.]), tensor([58.9767]))\n",
      "[tensor([[ 93.5481],\n",
      "        [224.6826]]), tensor([[187.2286],\n",
      "        [  2.4196]]), tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]), tensor([[280.7767],\n",
      "        [227.1022]])]\n"
     ]
    }
   ],
   "source": [
    "ad = ArithmeticDataset()\n",
    "print(next(iter(ad)))\n",
    "dataloader = torch.utils.data.DataLoader(ad, batch_size=2)\n",
    "print(next(iter(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrichidubey\u001b[0m (\u001b[33mrichidubey-georgia-institute-of-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "from torch.utils.data import DataLoader\n",
    "wandb.require(\"service\")\n",
    "\n",
    "\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2Config, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "def arithmetic_loss(predictions, targets, scale_factor=10000.0):\n",
    "    abs_error = (predictions - targets)**2\n",
    "    # rel_error = torch.abs((predictions - targets) / (targets + 1e-8)) * scale_factor\n",
    "    loss = abs_error # + rel_error\n",
    "    return torch.sum(loss)\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    num_epochs=6000,\n",
    "    batch_size=1024,\n",
    "    initial_lr=1e-3,\n",
    "    device='cuda',\n",
    "    # eval_every=500,\n",
    "    use_wandb=False,\n",
    "    project_name=\"arithmetic_training\"\n",
    "):\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=initial_lr)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.7)\n",
    "    \n",
    "    dataset = ArithmeticDataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=1, pin_memory=True, persistent_workers=True)\n",
    "    \n",
    "    steps_per_epoch = 10\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token  \n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "    tokenizer.padding_side = \"left\" \n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    # Initialize logging\n",
    "    if use_wandb:\n",
    "        wandb.init(project=project_name)\n",
    "        wandb.config.update({\n",
    "            \"learning_rate\": initial_lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"scheduler_step_size\": 200,\n",
    "            \"scheduler_gamma\": 0.7\n",
    "        })\n",
    "    else:\n",
    "        # Create CSV log file with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        log_file = f'training_log_{timestamp}.csv'\n",
    "        log_data = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_losses = []\n",
    "        epoch_diffs = []\n",
    "        \n",
    "        data_iter = iter(dataloader)\n",
    "        pbar = tqdm(range(steps_per_epoch), desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for step in pbar:\n",
    "            try:\n",
    "                batch = next(data_iter)\n",
    "            except StopIteration:\n",
    "                data_iter = iter(dataloader)\n",
    "                batch = next(data_iter)\n",
    "            \n",
    "            num1, num2, operation, targets = [item.to(device) for item in batch]\n",
    "            \n",
    "            # num1 = num1.unsqueeze(1)\n",
    "            # num2 = num2.unsqueeze(1)\n",
    "            ###############################\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            operation_mapping = {0: \"+\", 1: \"-\", 2: \"*\", 3: \"/\"}\n",
    "\n",
    "            # Decode the one-hot tensor into operation symbols\n",
    "            decoded_operations = [operation_mapping[torch.argmax(op).item()] for op in operation]\n",
    "\n",
    "            inp_txt = [\n",
    "                f\"{num1.item()} {op} {num2.item()}\" for num1, op, num2 in zip(num1, decoded_operations, num2)\n",
    "            ]\n",
    "\n",
    "            # print(\"INp text is \", inp_txt)\n",
    "            input_ids = tokenizer(inp_txt, return_tensors=\"pt\", padding=True, truncation = True)[\"input_ids\"].to(model.device)\n",
    "\n",
    "            output_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_new_tokens = 1,\n",
    "                num_return_sequences=1,  # Number of sequences to generate\n",
    "                do_sample=True,  # Enable sampling\n",
    "                top_k=50,  # Use top-k sampling\n",
    "                temperature=0.7,  # Sampling temperature\n",
    "            )\n",
    "\n",
    "            predicted_ids = output_ids\n",
    "\n",
    "            predictions = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)[-1]\n",
    "\n",
    "\n",
    "            ################################\n",
    "\n",
    "            try: \n",
    "                numeric_prediction = float(predictions)  # Only if it should be a number\n",
    "                predictions_tensor = torch.tensor([numeric_prediction]).to(device)  # Convert to tensor\n",
    "            except ValueError:\n",
    "                # print(f\"Decoded output is not numeric: {predictions}\")\n",
    "                predictions_tensor = torch.tensor([0.0], device=device, requires_grad=True)\n",
    "                \n",
    "            predictions =  predictions_tensor\n",
    "            loss = arithmetic_loss(predictions, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                diffs = torch.abs(predictions - targets)\n",
    "                epoch_diffs.extend(diffs.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({'Loss': loss.item()})\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            test_num1, test_num2, test_op, test_targets = [item.to(device) for item in next(iter(dataloader))]\n",
    "\n",
    "            ########################################\n",
    "\n",
    "            operation_mapping = {0: \"+\", 1: \"-\", 2: \"*\", 3: \"/\"}\n",
    "\n",
    "            # Decode the one-hot tensor into operation symbols\n",
    "            decoded_operations = [operation_mapping[torch.argmax(test_op).item()] for test_op in operation]\n",
    "\n",
    "            inp_txt = [\n",
    "                f\"{num1.item()} {test_op} {num2.item()}\" for num1, op, num2 in zip(test_num1, test_op, test_num2)\n",
    "            ]\n",
    "\n",
    "            # print(\"INp text is \", inp_txt)\n",
    "            input_ids = tokenizer(inp_txt, return_tensors=\"pt\", padding=True, truncation = True)[\"input_ids\"].to(model.device)\n",
    "\n",
    "            output_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_new_tokens = 1,\n",
    "                num_return_sequences=1,  # Number of sequences to generate\n",
    "                do_sample=True,  # Enable sampling\n",
    "                top_k=50,  # Use top-k sampling\n",
    "                temperature=0.7,  # Sampling temperature\n",
    "            )\n",
    "\n",
    "            predicted_ids = output_ids\n",
    "\n",
    "            predictions = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)[-1]\n",
    "\n",
    "            ################################\n",
    "\n",
    "            try: \n",
    "                numeric_prediction = float(predictions)  # Only if it should be a number\n",
    "                predictions_tensor = torch.tensor([numeric_prediction]).to(device)  # Convert to tensor\n",
    "            except ValueError:\n",
    "                # print(f\"Decoded output is not numeric: {predictions}\")\n",
    "                predictions_tensor = torch.tensor([0.0], device=device, requires_grad=True)\n",
    "                \n",
    "            test_pred =  predictions_tensor\n",
    "            ####################################################\n",
    "            \n",
    "            test_loss = arithmetic_loss(test_pred, test_targets)\n",
    "           \n",
    "            first_pred = test_pred[0].item()\n",
    "            first_target = test_targets[0].item()\n",
    "            \n",
    "            # Format to 5 decimal places\n",
    "            first_pred_formatted = f\"{first_pred:.5f}\"\n",
    "            first_target_formatted = f\"{first_target:.5f}\"\n",
    "            \n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            train_loss = np.mean(epoch_losses)\n",
    "            val_loss = test_loss.item()\n",
    "            avg_diff = np.mean(epoch_diffs)\n",
    "            median_diff = np.median(epoch_diffs)\n",
    "            \n",
    "            if use_wandb:\n",
    "                wandb.log({\n",
    "                    'learning_rate': current_lr,\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                    'avg_prediction_diff': avg_diff,\n",
    "                    'median_prediction_diff': median_diff,\n",
    "                    'epoch': epoch + 1\n",
    "                })\n",
    "            else:\n",
    "                log_data.append({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'learning_rate': current_lr,\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                    'avg_prediction_diff': avg_diff,\n",
    "                    'median_prediction_diff': median_diff\n",
    "                })\n",
    "            \n",
    "            print(\n",
    "                f'Epoch {epoch+1}/{num_epochs} | '\n",
    "                f'LR: {current_lr:.2e} | '\n",
    "                f'Train Loss: {train_loss:.4f} | '\n",
    "                f'Val Loss: {val_loss:.4f} | '\n",
    "                f'Avg Diff: {avg_diff:.4f} | '\n",
    "                f'First Pred: {first_pred_formatted} | '\n",
    "                f'First Target: {first_target_formatted}'\n",
    "            )\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        # Save the best model\n",
    "        if train_loss < best_loss:\n",
    "            best_loss = train_loss\n",
    "            torch.save(model.state_dict(), 'best_arithmetic_model.pt')\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1} completed. Average loss: {train_loss:.4f}\\n')\n",
    "    \n",
    "    if not use_wandb:\n",
    "        pd.DataFrame(log_data).to_csv(log_file, index=False)\n",
    "        print(f\"Training log saved to {log_file}\")\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrichidubey\u001b[0m (\u001b[33mrichidubey-georgia-institute-of-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hice1/rdubey36/repos/ALU4LLMs/wandb/run-20241207_021437-e4dnw5m0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/richidubey-georgia-institute-of-technology/arithmetic_training/runs/e4dnw5m0' target=\"_blank\">stellar-wind-27</a></strong> to <a href='https://wandb.ai/richidubey-georgia-institute-of-technology/arithmetic_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/richidubey-georgia-institute-of-technology/arithmetic_training' target=\"_blank\">https://wandb.ai/richidubey-georgia-institute-of-technology/arithmetic_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/richidubey-georgia-institute-of-technology/arithmetic_training/runs/e4dnw5m0' target=\"_blank\">https://wandb.ai/richidubey-georgia-institute-of-technology/arithmetic_training/runs/e4dnw5m0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.56it/s, Loss=2.05e+7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | LR: 1.00e-04 | Train Loss: 19971137.2000 | Val Loss: 19087596.0000 | Avg Diff: 258.9499 | First Pred: 0.00000 | First Target: 270.26447\n",
      "Epoch 1 completed. Average loss: 19971137.2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.13it/s, Loss=1.92e+7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | LR: 1.00e-04 | Train Loss: 19189882.6000 | Val Loss: 18600274.0000 | Avg Diff: 253.8488 | First Pred: 0.00000 | First Target: 383.72769\n",
      "Epoch 2 completed. Average loss: 19189882.6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.19it/s, Loss=1.88e+7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | LR: 1.00e-04 | Train Loss: 19483807.2000 | Val Loss: 19240972.0000 | Avg Diff: 255.4323 | First Pred: 0.00000 | First Target: 289.17603\n",
      "Epoch 3 completed. Average loss: 19483807.2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20:  10%|█████████▊                                                                                        | 1/10 [00:00<00:06,  1.36it/s, Loss=1.97e+7]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 123\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, batch_size, initial_lr, device, use_wandb, project_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m predictions \u001b[38;5;241m=\u001b[39m  predictions_tensor\n\u001b[1;32m    121\u001b[0m loss \u001b[38;5;241m=\u001b[39m arithmetic_loss(predictions, targets)\n\u001b[0;32m--> 123\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    125\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "train_model(customModel, num_epochs=20, batch_size=256, initial_lr=1e-4, device='cuda', use_wandb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cv_proj4]",
   "language": "python",
   "name": "conda-env-.conda-cv_proj4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05f5aa7d478e4fc4a766718438cae2de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ea78e20a596498c834fb068380c2a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "201b97b8813d41a4b7661d9f92e098ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "228a14a890c74f81a58ecf89759b2539": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c8b07c27f3242c8884aafe596e6a78d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e528a25513642a1bdc357462a93d6f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca9af9908ea1428fb9e3a7463a53b78b",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_87a5ba1d542b46668992e5d4f07909b7",
      "value": 665
     }
    },
    "3799256f111445e8b19eb4c7da57f16d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3dc783062d1d48339ce06229684cacba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b970dbe014d243299e909c5b954e02c4",
      "max": 548105171,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3799256f111445e8b19eb4c7da57f16d",
      "value": 548105171
     }
    },
    "40d06beaf3184bab820b838f307eced0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1b7aa63a2b54b0da9fbb42cf150224f",
       "IPY_MODEL_2e528a25513642a1bdc357462a93d6f3",
       "IPY_MODEL_a661439821e644c489abdf913dde2f7f"
      ],
      "layout": "IPY_MODEL_228a14a890c74f81a58ecf89759b2539"
     }
    },
    "485bbc552f87497e80485c868face717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d25b4beee8524b5db6c24d791165f9c4",
       "IPY_MODEL_3dc783062d1d48339ce06229684cacba",
       "IPY_MODEL_d91d67a1f0154660adbda90e3a4121ed"
      ],
      "layout": "IPY_MODEL_5909802c97724dcebba8268a0a511677"
     }
    },
    "527f56197cd649288b70c0f5d5510117": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5909802c97724dcebba8268a0a511677": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6db22affb0f74625bb174564a940a4e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87a5ba1d542b46668992e5d4f07909b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a661439821e644c489abdf913dde2f7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05f5aa7d478e4fc4a766718438cae2de",
      "placeholder": "​",
      "style": "IPY_MODEL_1ea78e20a596498c834fb068380c2a44",
      "value": " 665/665 [00:00&lt;00:00, 39.4kB/s]"
     }
    },
    "b970dbe014d243299e909c5b954e02c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca9af9908ea1428fb9e3a7463a53b78b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d25b4beee8524b5db6c24d791165f9c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_201b97b8813d41a4b7661d9f92e098ab",
      "placeholder": "​",
      "style": "IPY_MODEL_527f56197cd649288b70c0f5d5510117",
      "value": "model.safetensors: 100%"
     }
    },
    "d91d67a1f0154660adbda90e3a4121ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c8b07c27f3242c8884aafe596e6a78d",
      "placeholder": "​",
      "style": "IPY_MODEL_6db22affb0f74625bb174564a940a4e5",
      "value": " 548M/548M [00:02&lt;00:00, 241MB/s]"
     }
    },
    "ddf6e3191347473ab221282bc6befa06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1b7aa63a2b54b0da9fbb42cf150224f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddf6e3191347473ab221282bc6befa06",
      "placeholder": "​",
      "style": "IPY_MODEL_f1edee125e2145a0aaccdbcebcd5184e",
      "value": "config.json: 100%"
     }
    },
    "f1edee125e2145a0aaccdbcebcd5184e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
